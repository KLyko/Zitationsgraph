
Adams, B., Lin, C.-Y., and Iyengar, G. (2002).
IBM Multimodal Annotation Tool. http://www.alpha
works.ibm.com/tech/multimodalannotation (accessed
4 January 2007).
AHRC, Arts and Humanitites Research Council (2003).
Research subject coverage. http://www.ahrc.ac.uk/
about/subject_coverage/research_subject_coverage.asp
(accessed 4 January 2007).
Allan, J. (2003). Robust techniques for organizing and
retrieving spoken documents. EURASIP Journal on
Applied Signal Processing, 2003, 103–114. doi: 10.1155/
S1110865703211070. http://www.hindawi.com/
GetArticle.aspx?doi¼10.1155/S1110865703211070
(accessed 4 January 2007).
Amatriain, X., Massaguer, J., Garcia, D., and
Mosquera, I. (2005). The CLAM Annotator: A Cross-
platform Audio Descriptors Editing Tool. In
Proceedings of the Sixth International Conference on
Music Information Retrieval, London, 426–9. http://
www.iua.upf.edu/mtg/publications/9317d2-ismir2005-
clam-annotator.pdf (accessed 4 January 2007).
Amir, A., Srinivasan, S., and Efrat, A. (2002). Search the
Audio, Browse the Video—A Generic Paradigm for
Video Collections. http://www.hindawi.com/GetArticle.
aspx?Doi¼10.1155/S111086570321012X&e¼CTA
(accessed 4 January 2007).
Annodex (2006). http://www.annodex.net/ (accessed
4 January 2007).
Arons, B. (1997). SpeechSkimmer: A System for
Interactively Skimming Recorded Speech. ACM
Transactions on Computer-Human Interaction, 4: 3–38,
http://xenia.media.mit.edu/~barons/html/tochi97.html
(accessed 4 January 2007).
BBC, British Broadcasting Corporation (2003a).
Creative Licence Group. http://creativearchive.bbc.
co.uk/ (accessed 4 January 2007).
BBC, British Broadcasting Corporation (2006).
BBC Programme Catalogue. http://open.bbc.co.uk/
catalogue/infax (accessed 4 January 2007).
BBN Technologies (2004–06). IdentiFinder. http://
www.bbn.com/Solutions_and_Technologies/Data_
Indexing_and_Mining/Identifinder.html (accessed
4 January 2007).
Black and Ethnic Minority Experience (2002). http://
www.be-me.org/ (accessed 4 January 2007).
Blinkx (2006). blinkx.tv http://tv.blinkx.com/ (accessed
4 January 2007).
British Academy (2005). E-Resources for Research in the
Humanities and Social Sciences—A British Academy
Policy Review. http://www.britac.ac.uk/reports/
eresources/index.html (accessed 4 January 2007).
British Academy (2006). Copyright and Research in the
Humanities and Social Sciences. http://www.britac.ac.
uk/reports/copyright/index.html (accessed 4 January
2007).
British Library (2006). Intellectual Property: A balance;
The British Library manifesto, http://www.bl.uk/news/
pdf/ipmanifesto.pdf (accessed 4 January 2007).
BUFVC, British Universities Film and Video
Council (2004). Hidden Treasures: the UK
Audiovisual Archive Strategic Framework. http://
www.bufvc.ac.uk/faf/HiddenTreasures.pdf (accessed
4 January 2007).
BUFVC, British Universities Film and Video Council
(2006). Moving Image Gateway. http://www.bufvc.ac.
uk/gateway/ (accessed 4 January 2007).
Church, K. W. (2003). Speech and Language Processing:
Where Have We Been and Where Are We Going?
In Proceedings of EUROSPEECH 2003, 8th European
Conference on Speech Communication and Technology,
Geneva, 1–4. http://research.microsoft.com/users/
church/wwwfiles/papers/Eurospeech/2003/ES032000.
pdf (accessed 4 January 2007).
CNN, Cable News Network (2006). Image Source. http://
www.cnnimagesource.com/CNIS/index.html (accessed
4 January 2007).
Creative Commons (2006). Enabling the Legal Sharing
and Reuse of Cultural, Educational, and Scientific
Works. http://creativecommons.org/ (accessed 4
January 2007).
Dixon, S. and Widmer, G. (2005). MATCH: A Music
Alignment Tool Chest. In Proceedings of the Sixth
International Conference on Music Information Retrieval
(ISMIR 2005), London, 492–497. http://www.ofai.at/
cgi-bin/tr-online?numberþ2005-17 (accessed 4 January
2007).
Dixon, S. (2005). MATCH, Music Alignment Tool Chest.
http://www.ofai.at/simon.dixon/match/index.html
(accessed 4 January 2007).
Edina (2006). Film and Sound Online. http://www.
filmandsound.ac.uk (accessed 4 January 2007).
A. Marsden et al.
484 Literary and Linguistic Computing, Vol. 22, No. 4, 2007
 at U
B Leipzig on D
ecem
ber 9, 2011
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
Fiscus, J. G., Radde, N., Garofolo, J., Le, A., Ajot, J., and
Laprun, C. (2005). The Rich Transcription 2005 Spring
Meeting Recognition Evaluation. http://www.nist.gov/
speech/publications/papersrc/rt05sresults.pdf (accessed
4 January 2007).
Fitzgerald, R. A. (2003). Performer-Dependent Dimensions
of Timbre: Identifying Acoustic Cues for Oboe Tone
Discrimination. Ph.D. Thesis, School of Music,
University of Leeds.
FreeSound (2006). The Freesound Project. http://
freesound.iua.upf.edu/ (accessed 4 January 2007).
Furui, S. (2005a). 50 Years of Progress in Speech and
Speaker Recognition. In Proceedings of SPECOM 2005,
Patras, Greece, 1–9. Preprint: http://www.furui.cs.
titech.ac.jp/publication/2005/SPCOM05.pdf (accessed
4 January 2007).
Furui, S. (2005b). Spontaneous Speech Recognition and
Summarization, The Second Baltic Conference on
Human Language Technologies, 39–50. http://
www.furui.cs.titech.ac.jp/publication/2005/
HLT2005.pdf (accessed 4 January 2007).
Gauvain, J.-L. and Lamel, L. (2003). Structuring
Broadcast Audio for Information Access. EURASIP
Journal on Applied Signal Processing, 2003(2): 140–50.
http://www.hindawi.com/GetArticle.aspx?doi=10.1155/
S1110865703211033 (accessed 4 January 2007).
Goldman, J., Renals, S., Bird, S. et al. (2005).
Accessing the Spoken Word. International Journal on
Digital Libraries, 5(4): 287–98. doi: 10.1007/s00799-
004-0101-0. Preprint: http://www.cstr.ed.ac.uk/
downloads/publications/2005/swag-ijdl05.pdf, full pro-
ject report: http://www.dcs.shef.ac.uk/spandh/projects/
swag/swagReport.pdf (accessed 4 January 2007).
Gomez, E. and Bonada, J. (2005). Tonality
Visualization of Polyphonic Audio. In Proceedings of
the International Computer Music Conference,
Barcelona, 57–60.
Gonet, W. and S´wiecin´ski, R. (2002). Speech Lab @
Work and @ Home. Speech and Language Technology, 6,
57–80, Polish Phonetic Association.
Google (2006a). Nara on Google Video. http://video.
google.com/nara.html (accessed 4 January 2007).
Google (2006b). Google Video. http://video.google.co.uk/
(accessed 4 January 2007).
Google (2006c). Google Video Upload Program. http://
upload.video.google.com/ (accessed 4 January 2007).
Gracenote (2006). Gracenote Music Fans. http://
www.gracenote.com (accessed 4 January 2007).
Hauptmann, A. (2005). Lessons for the Future from
a Decade of Informedia Video Analysis Research.
http://www.informedia.cs.cmu.edu/documents/
CIVR05_Hauptmann.pdf (accessed 4 January 2007).
Howard-Spink, S. (n.d.). You just don’t understand!
http://domino.watson.ibm.com/comm/wwwr_think
research.nsf/pages/20020918_speech.html (accessed
4 January 2007).
HUMBUL (2006). Intute: Arts and Humanities. http://
www.intute.ac.uk/artsandhumanities/langlit-all/
(accessed 4 January 2007).
IBM, International Business Machines (2006).
Marvel. http://domino.research.ibm.com/comm/
research_projects.nsf/pages/marvel.index.html
(accessed 4 January 2007).
IDIAP Research Institute (2006). Ferret Meeting
Browser Demo. http://mmm.idiap.ch/demo/ (accessed
4 January 2007).
IMDb (2006). The Internet Movie Database. http://
www.imdb.com/ (accessed 4 January 2007).
Imperial War Museum (2006a). IWM Collections
Online. http://www.iwmcollections.org.uk/ (accessed
4 January 2007).
Information Systems Research Laboratory, University
of Illinois (2005), M2K (Music-to-Knowledge): A Tool
Set for MIR/MDL Development and Evaluation. http://
www.music-ir.org/evaluation/m2k/ (accessed 4 January
2007).
Isaacson, E. (2005). What You See is What You Get: On
Visualizing Music. In Proceedings of the Sixth
International Conference on Music Information
Retrieval, London, 389–95. http://ismir2005.ismir.net/
proceedings/1129.pdf (accessed 4 January 2007).
ISMIR (n.d.). The International Conferences on Music
Information Retrieval and Related Activities. http://
www.ismir.net/ (accessed 4 January 2007).
JISC (2006). JISC Digitisation Program. http://www.jisc.
ac.uk/digitisation_home.html (accessed 4 January
2007).
Klapuri, A. (2004). Automatic Music Transcription
As We Know it Today. Journal of New Music
Research, 33: 269–82.
Koumpis, K. and Renals, S. (2001). The Role of Prosody
in Voicemail Summarization Systems. ISCA Workshop
on Prosody in Speech Recognition and Understanding.
NJ: Red Bank(accessed 4 January 2007).
Koumpis, K. and Renals, S. (2005). Content-based Access
to Spoken Audio. IEEE Signal Processing Magazine,
Tools for Research with Speech, Music, Film, Video
Literary and Linguistic Computing, Vol. 22, No. 4, 2007 485
 at U
B Leipzig on D
ecem
ber 9, 2011
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
22(5): 61–90. Preprint: http://www.cstr.ed.ac.uk/down
loads/publications/2005/koumpis-spm05.pdf (accessed
4 January 2007).
Le, A. (2004). 2004 Fall Rich Transcription Speech-to-
Text Evaluation. http://www.nist.gov/speech/tests/rt/
rt2004/fall/rt04f-stt-results-v6b.pdf (accessed
4 January 2007).
Lee, L. and Chen, B. (2005). Spoken Document
Understanding and Organization. IEEE Signal Proces-
sing Magazine, 22(5): 42–60. http://ieeexplore.ieee.org/
xpl/freeabs_all.jsp?isnumber=32367&arnumber=15118
23&count=17&index=4 (accessed 4 January 2007).
Linguistic Data Consortium (2001). Linguistic
Annotation. http://www.ldc.upenn.edu/annotation/
(accessed 4 January 2007).
Liu, Y., Shriberg, E., Stolcke, A., et. al. (2005). Structural
Metadata Research in the EARS Program. IEEE
International Conference on Acoustics, Speech, and
Signal Processing, 2005. Proceedings (ICASSP ‘05), 5,
957–60. http://ieeexplore.ieee.org/xpl/RecentCon.jsp?
punumber¼9711, Digital Object Identifier 10.1109/
ICASSP.2005.1416464. Preprint: http://www.icsi.
berkeley.edu/yangl/icassp2005-mde.pdf (accessed
4 January 2007).
Llisterri, J. (2006). Speech Analysis and Transcription
Software. http://liceu.uab.es/joaquim/phonetics/
fon_anal_acus/herram_anal_acus.html (accessed
4 January 2007).
Logan, B., Moreno, P., and Van Thong, J. M. (2003).
Approaches to Reduce the Effects of OOV Queries on
Indexed Spoken Audio. Technical Report HPL-2003-46,
HP Laboratories Cambridge. http://citeseer.ist.psu.edu/
logan03approaches.html (accessed 4 January 2007).
Lyman, P. andVarian,H. (2003). How Much Information?
http://www2.sims.berkeley.edu/research/projects/how-
much-info-2003/ (accessed 4 January 2007).
Marsden, A., Nock, H., Mackenzie, A., Lindsay, A.,
Coleman, J., and Kochanski, G. (2006). ICT Tools for
Searching, Annotation and Analysis of Audiovisual
Media. AHRC ICT Strategy Project report. On-line
version at http://www.phon.ox.ac.uk/avtools, mirrored
at http://ict4av.lancs.ac.uk/report. (accessed 4 January
2007).
MeeVee (2006). http://www.meevee.com/ (accessed
4 January 2007).
Meredith, D. (2006). The ps13 Pitch Spelling Algorithm.
Journal of New Music Research, 35: 121–59.
MIREX (n.d.). http://www.music-ir.org/mirexwiki/index.
php/Main_Page (accessed 4 January 2007).
MIT, Massachusets Institute of Technology (2006).
Welcome to DSpace. http://www.dspace.org (accessed
4 January 2007).
Miyamori, H., Stejic, Z., Araki, T., Minakuchi, M., and
Ma, Q. (2006). Proposal of Integrated Search Engine of
Web and TV Contents. In Proceedings of WWW2006,
15th World Wide Web Conference, Edinburgh. http://
www2006.org/programme/files/pdf/p190.pdf (accessed
4 January 2007).
Moore, R. (2003). A Comparison of the Data Require-
ments of Automatic Speech Recognition Systems and
Human Listeners. In Proceedings of EUROSPEECH 2003,
8th European Conference on Speech Communication and
Technology, Geneva, 2582–4. http://www.dcs.shef.ac.uk/
roger/publications/Eurospeech03%20Comparison%
20of%20Data%20Requirements.pdf (accessed 4 January
2007).
MTG, Pompeu Fabra University (2006). http://iua-
share.upf.es/wikis/clam/index.php/Music_Annotator
(accessed 4 January 2007).
Naxos (2006). Naxos Music Library. http://www.
naxosmusiclibrary.com (accessed 4 January 2007).
NCeSS, National Centre for e-Social Science (2005).
MixedMediaGrid. http://www.ncess.ac.uk/research/
nodes/MiMeG/ (accessed 4 January 2007).
NCHSwiftSound (2006). Express Scribe Transcription
Playback Software. http://www.nch.com.au/scribe/
index.html (accessed 4 January 2007).
net imperative (2006). Blinkx launches ad-funded video
service. http://www.netimperative.com/2006/02/08/
Blinkx_ITN (accessed 4 January 2007).
News.com (2006). Google puts National Archives Video
Online. http://news.com.com/GoogleþputsþNational
þArchivesþvideoþonline/2100-1025_3-6043193.html
(accessed 4 January 2007).
NYU, New York University (n.d.). Query by Humming.
http://querybyhum.cs.nyu.edu/ (accessed 4 January
2007).
Ostendorf, M., Shriberg, E., and Stolcke, A. (2005).
Human Language Technology: Opportunities and
Challenges. In Proceedings of IEEE International
Conference on Acoustics, Speech, and Signal
Processing, 2005. (ICASSP’05), 5, 949–52. http://
ieeexplore.ieee.org/xpl/RecentCon.jsp?punumber¼
9711, Digital Object Identifier 10.1109/ICASSP.2005.
1416462. Preprint: http://www.speech.sri.com/papers/
icassp2005-specialsession.pdf (accessed 4 January 2007).
Pardo, B. and Birmingham, W.P. (2003). Query by
Humming: How Good Can it Get? In J.S. Downie (ed.),
A. Marsden et al.
486 Literary and Linguistic Computing, Vol. 22, No. 4, 2007
 at U
B Leipzig on D
ecem
ber 9, 2011
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
The MIR/MDL Evaluation Project White Paper
Collection, 3rd edn, 107–9. http://www.music-ir.
org/evaluation/wp3/wp3_pardo_query.pdf (accessed
4 January 2007).
Peeters, G., La Burthe, A., and Rodet, X. (2002). Toward
Automatic Music Audio Summary Generation from
Signal Analysis. In Proceedings of the 3rd International
Conference on Music Information Retrieval (ISMIR
2002), Paris. http://recherche.ircam.fr/equipes/analyse-
synthese/peeters/ARTICLES/Peeters_2002_ISMIR_
AudioSummary.pdf (accessed 4 January 2007).
Pickering, M. (2006). Automatic News Summarization
Extraction System. http://wwwhomes.doc.ic.ac.uk/
mjp3/anses/ (accessed 4 January 2007).
Pickering, M. J., Wong, L., and Ru¨ger, S. M. (2003).
ANSES – Summarisation of News Video. In Proceedings
of International Conference on Image and Video
Retrieval (CIVR-2003). Lecture Notes in Computer
Science 2728 (Springer), 425–34. http://www.doc.
ic.ac.uk/mjp3/phd/www-pub/civr2003.pdf (accessed
4 January 2007).
The Poetry Archive (2005). http://www.poetryarchive.org
(accessed 4 January 2007).
Praktische Informatik IV, University of Mannheim
(2006). Automatic Movie Content Analysis: The MoCA
Project. http://www.informatik.uni-mannheim.de/pi4.
data/content/projects/moca/ (accessed 4 January 2007).
Prelinger Archives (2006). http://www.archive.org/
details/prelinger (accessed 4 January 2007).
Price, G. (2006). Searching for Online Video. http://
searchenginewatch.com/searchday/article.php/3576231
(accessed 4 January 2007).
Radio Times (2006). http://www.radiotimes.com/
(accessed 4 January 2007).
Rapaport, E. (2004). Schoenberg-Hartleben’s Pierrot
Lunaire: Speech – Poem – Melody – Vocal
Perforamnce. Journal of NewMusic Research, 33: 71–111.
Resolume (n.d.). Resolume VJ Software. http://www.
resolume.com/features/index.php (accessed 4 January
2007).
Sandom, C. and Enser, P. (2003). Archival Moving
Imagery in the Digital Environment. In Anderson, J.,
Dunning, A., and Fraser, M (eds), Digital Resources for
the Humanities 2001–2002. London: Office for
Humanities Communication, King’s College. http://
www.cmis.brighton.ac.uk/research/vir/DRH2001.pdf
(accessed 4 January 2007).
Sjo¨lander, K. and Beskow, J. (2000). WaveSurfer – An
Open Source Speech Tool. In Proceedings of ICSLP,
Beijing, Oct 16–20, 4:464–467. http://www.speech.kth.
se/wavesurfer/wsurf_icslp00.pdf (accessed 4 January
2007).
Sjo¨lander, K. and Beskow, J. (2006). Wavesurfer. http://
www.speech.kth.se/wavesurfer/ (accessed 4 January
2007).
St George’s, Leeds (2006). Sermons. http://www.
stgeorgesleeds.org.uk/church/sermons.htm (accessed
4 January 2007).
SWAG, Spoken Word Archive Group (2003). Report
of the EU/US Working Group on Spoken Word
Digital Audio. http://www.dcs.shef.ac.uk/spandh/
projects/swag/swagReport.pdf (accessed 4 January
2007).
Tanghe, K., Lesaffre, M., Degroeve, S., Leman, M.,
De Baets, B., and Martens, J.-P. (2005)
Collecting Ground Truth Annotations for Drum
Detection in Polyphonic Music. In Proceedings
of the Sixth International Conference on Music
Information Retrieval, London, 50–57. http://
ismir2005.ismir.net/proceedings/1006.pdf (accessed
4 January 2007).
The MathWorks (1994–2006). MATLAB. http://
www.mathworks.com/products/matlab/ (accessed 4
January 2007).
Transcriber (2006). A Tool for Segmenting, Labeling and
Transcribing Speech. http://sourceforge.net/projects/
trans/ (accessed 4 January 2007).
Tranter, S. and Reynolds, D. (2006). An Overview of
Automatic Speaker Diarisation Systems. IEEE
Transactions on Speech and Audio Processing, 14:
1557–65. http://www.ll.mit.edu/IST/pubs/0511_
Reynolds1.pdf (accessed 4 January 2007).
Tucker, S. and Whittaker, S. (2005). Novel Techniques
for Time-compressing Speech: An Exploratory Study.
International Conference on Acoustics, Speech and Signal
Proceessing, Philadelphia. http://www.dcs.shef.ac.uk/
sat/downloads/ICASSP2005.pdf (accessed 4 January
2007).
Tzanetakis G. (n.d.). MARSYAS: Music Analysis,
Retrieval and Synthesis for Audio Signals. http://
opihi.cs.uvic.ca/marsyas/ (accessed 4 January 2007).
Tzanetakis, G. and Cook, P. (1999). MARSYAS: a
Framework for Audio Analysis. Organised Sound, 4:
169–175. http://www.cs.uvic.ca/~gtzan/work/pubs/
organised00gtzan.pdf (accessed 5 July 2007).
UCLA Film & Television Archive (n.d.). Digital
Hitchcock, http://www.cinema.ucla.edu/education/
dighitch.html (accessed 4 January 2007).
Tools for Research with Speech, Music, Film, Video
Literary and Linguistic Computing, Vol. 22, No. 4, 2007 487
 at U
B Leipzig on D
ecem
ber 9, 2011
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
UCSB, University of California Santa Barbara (2006).
Cylinder Preservation Project. http://cylinders.library.
ucsb.edu (accessed 4 January 2007).
van Leeuwen, D., Martin, A., Przymocki, M., and
Bouten, J. (2006). NIST and NFI-TNO Evaluations of
Automatic Speaker Recognition. Computer Speech and
Language, 20: 128–58.
Virage (2006). Virage Products Overview. http://www.
virage.com/content/products/ (accessed 4 January 2007).
Volkmer, T. (2006). Efficient Video Annotation
(EVA) System. http://domino.research.ibm.com/
comm/research.nsf/pages/r.multimedia.innovation.
html?Open&printable (accessed 4 January 2007).
WCER, Wisconsin Center for Education Research,
University of Wisconsin (2006). Transana. http://
www.transana.org/ (accessed 4 January 2007).
Youtube (2006). Broadcast Yourself. http://www.youtube.
com/ (accessed 4 January 2007).
A. Marsden et al.
488 Literary and Linguistic Computing, Vol. 22, No. 4, 2007
 at U
B Leipzig on D
ecem
ber 9, 2011
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
