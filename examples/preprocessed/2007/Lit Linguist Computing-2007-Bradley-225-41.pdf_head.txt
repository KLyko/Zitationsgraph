Supporting Annotation as a
Scholarly Tool—Experiences From
the Online Chopin Variorum Edition
............................................................................................................................................................
John Bradley and Paul Vetch
Centre for Computing in the Humanities, King’s College London,
UK
.......................................................................................................................................
Abstract
In a meeting at King’s College London in May 2000, John Unsworth proposed a list
of seven ‘scholarly primitives’ which he claimed were ‘self-understood’ functions
forming the basis for ‘higher-level scholarly projects, arguments, statements [and]
interpretations’ (Unsworth, 2000). He claimed that his list summarized activities
that were ‘basic to scholarship across eras and across media’, and went on to say
that an analysis of these scholarly primitives might result in a clearer sense of how
computing tools could support the scholarly endeavour. Here we focus on the
primitive that was second on Unsworth’s list, after ‘Discovering’: ‘Annotation’.
Our work on annotation arises out of a developing awareness that established
Humanities Computing (HC) areas of interest, do not seem always to connect with
the actual process of the research work being carried out by most humanists. We
claimed in Bradley (2005) that a fundamentally different usage paradigm than those
in operation in established HC was necessary to even notice, and then follow-up
on, the potential of scholarly annotation as a computer-supported activity.
This article presents our experiences, and the eventual outcomes, of the process
of developing annotations tools for the Online Chopin Variorum Edition project
(OCVE).1 Beginning with a brief overview of activities related to annotation in
Humanities Computing and Computing Science, we introduce the visible parts of
the OCVE project, and address some discussion to the structures behind the
scenes that support what it does, reporting what worked and what did not. We
conclude by analysing the significance of our findings and describing the
direction we think our annotation tool will take.
.................................................................................................................................................................................