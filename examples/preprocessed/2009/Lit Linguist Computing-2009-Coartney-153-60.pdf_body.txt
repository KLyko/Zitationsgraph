
Imagine you are watching a dance captured on
video. On the screen you see four women, dressed
in various shades of blue, moving singly, and in
unison (Fig. 1). They dance on a stage bereft of
props or backdrop, lit only by dim amber lights
shining on them from low angles. Recorded music
accompanies the movement and supports the mood
of the piece, entitled For Natalie. It is a fairly basic
work, as dance works go: pedestrian costumes, a few
lights, music, dancers, and movement. And yet, it is
hardly as straightforward as you may think
(Adshead-Lansdale, 1999; Goellner, 1995). Aside
from the fact that no dance is straightforward, in
that the art of dance is inherently multi-layered by
virtue of the artistic idea being transmitted through
corporeal action in space, the 1-min film clip you
watch demonstrates the added complexity of film. It
is an edited form of the dance work, a short clip
Correspondence:
Susan L. Wiesner,
Executive Director,
Dance Heritage Coalition,
1111 16th Street, NW,
Suite 300, Washington,
DC 20036, USA.
E-mail:
swiesner@danceheritage.org
Literary and Linguistic Computing, Vol. 24, No. 2, 2009.  The Author 2009. Published by Oxford University Press on
behalf of ALLC and ACH. All rights reserved. For Permissions, please email: journals.permissions@oxfordjournals.org
153
doi:10.1093/llc/fqp012
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
selected from a 15-min dance work captured by
a single gaze, a static camera, placed in an arbitrary
location, on an evening that suited our schedule.
It does not show the process of creating the work,
the choreographer’s ideas, the inspiration and moti-
vation for the work, her movement choices. In fact,
there is much to say about the somewhat unusual
choreographic processes involved in this work, as it
was choreographed as part of ARTeFACT, a project
developed to study the generation, preservation, and
re-purposing of data gathered from dance
movement.
For more than ten years those in the discipline of
dance, and the performing arts, have discussed digi-
tal technologies and questioned their use to pro-
duce, ‘preserve, and make accessible’ dance
artefacts (Nichols, 1997, p. 187). Indeed, several
libraries have funded projects that acknowledge
the need to document movement-based texts; how-
ever, as the following quotes and others demon-
strate, many issues continue to exist as librarians,
archivists, artists, and historians address the inclu-
sion of digitized dance artefacts in library reposi-
tories and archives.
Although digital technologies can incorporate
filmic ways of perceiving [the performing
arts], that is the tip of the iceberg. It is impor-
tant for us to anticipate that there are other
forms we can use for documentation rather
than limiting ourselves to the tradition of a
camera in front of the stage. Documentation
within a digital environment far exceeds the
filmic way of looking at a performance.
Ashley 2005 quoted in NYPL Working Group
4, 5
How can new technology both support the
information we think is valuable, but also
put it in a format that the next generation is
going to understand and make use of?
Mitoma 2005 quoted in NYPL Working
Group 4, 6
As these quotes note, for the most part, the dis-
course centres around filmic means of digitizing and
preserving dance; however, some researchers suggest
that other tools can be used to preserve dance move-
ment. One dance artist and scholar, Lisa Naugle,
notes that motion capture techniques ‘provide his-
torical dance information; historical in that data are
immediately available at the time movement is cap-
tured and can, therefore, be used later in different
ways by different people, for reinterpretation’
(Naugle, 2001, p. 76). Naugle’s purpose, however,
is not to preserve the data for posterity or for study,
so much as it is to use the data to enable animation
and virtual dance. Other researchers have posited
that preserved motion capture data can facilitate
further study of dance. In fact, the Dance Heritage
Coalition included motion capture as a technique
Fig. 1 A single video frame chosen from thousands to represent a 1-min video clip of the April 2008 performance of
For Natalie (Stalnaker, 2008)
J. S. Coartney and S. L. Wiesner
154 Literary and Linguistic Computing, Vol. 24, No. 2, 2009
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
for documenting dance for historical and anthropo-
logical study (DHC, 2006). As valuable as motion
capture can be, it considers only the movement and
the personal kinesphere; there is no relation to
external space per se nor to dynamics of the move-
ment. Labanotation, a graphic depiction of dance
movements and space which can be generated
through a computer application, can offer a means
of seeing individual bodies in relation to space, as it
can describe the movement and directional space.
So, too, does Laban’s effort-shape analysis—euki-
netics—describe dynamics. Yet as valuable as nota-
tion and motion capture are for providing some
means of preserving dance movement, they cannot
offer a complete picture of a dance, as neither takes
into account the multiple elements that together
constitute a dance.1 Further, these methods dis-
count entirely the preservation of born-digital ele-
ments created during an interactive performance.
Motion capture, however, is a method used
create digital elements in dance works including
interactive technologies. In fact, dance has long
used technology in production, especially in the
C20 within the modern dance world. Examples of
this would be the work that Alwin Nikolias created
through interactive technologies in the 1950s and
1960s (Nikolais commissioned the first commercial
Moog synthesizer in 1964 for his dance company),
the work developed in Denmark with Robert
Wechsler and the Palindrome Dance Company
using EKG transmissions and other technologies,
and the motion capture work that Shelley Eshkar
and Paul Kaiser performed with choreographers
Merce Cunningham (designer of Life Forms chor-
eographic software) and Bill T. Jones (multi-media
choreographer), to name but a few. This is work
that definitely has the ‘cool’ factor in performance.
But again, how does one capture that production
element among the many elements involved in the
dance? How do we preserve it, and further, why? It
is our hope that through the ARTeFACT project we
can answer some—if not all—of these questions.
1 The Project
The ARTeFACT project is not above ‘cool’ as in its
initial stages, the project was imagined as one of
those production projects invoking the spirit of
Nikolais, yet using newer technologies such as the
Wii and a Mac, with the collaboration of a choreo-
grapher and a group of first year engineering stu-
dents. In its first phase, ARTeFACT (project Alpha)
included six teams of students in an Introductory
Engineering Class, designed and taught by Professor
Brad Bennett, Research Director at University of
Virginia Kluge Institute. Each team was asked to
design and build an orthotic device that, when
worn, causes the wearer to emulate the challenges
of walking with a physical disability.2 During the
course of the semester, the student teams captured
pre-event processes in a variety of digital formats:
still and video images of the prototypes from cam-
eras and cell phones, PDF files, mathCAD drawings,
PowerPoint files, and video documentation of their
in-class presentations (Fig. 2). In lieu of a final
exam, the students produced a performance
during which members of each group wore their
devices and moved through the space according to
‘choreography’ set by their peers.
Adding to the complexity, the performance drew
on the wide variety of supporting, media rich,
source material created during the course of the
semester, as part of an interactive event. In addition
to the previously mentioned student teams develop-
ing orthotic devices, two other teams were assigned
the task of developing wireless measurement sensors
which, when attached to each orthotic device, mea-
sured the impact of the device on the gait of the
wearer. The sensors then transmitted the measure-
ment data to a computer that fed the data into a
software application, Max/MSP/Jitter, designed to
take advantage of data streams. The software created
real-time data visualization as output. The resultant
audio visual montage played as the backdrop to
their final production, Walk Don’t Run.
When planning the project, several methods for
transmitting data were considered: radio frequen-
cies, wireless ethernet, infrared light, and
Bluetooth. Bluetooth specifications met all of the
design requirements for the project, and the stu-
dents had immediate access to a variety of
Bluetooth options, including Nintendo Wiimotes,
a gaming interface, as well as the Newton Apple, a
sophisticated, medical-grade, six-degrees-of-
Performance as digital text
Literary and Linguistic Computing, Vol. 24, No. 2, 2009 155
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
freedom sensor for measuring movement developed
by a local R&D company, Barron & Associates (see
Fig. 3). While the Newton Apple was the more
sophisticated and preferred device, the Nintendo
Wiimotes offered the advantage of existing and
proven connectivity.
Max/MSP/Jitter treats all data as a series of data-
streams, with patches controlling the signals. The
performance patch (Fig. 4) samples data streams
from the Wiimotes and dynamically generates a
video performance element. The critical compo-
nents of the patch are (i)connecting and sampling
the sensor data; (ii) randomly choosing source data
to be processed; (iii) processing the source data to
create a new ‘real-time’ performance element; (iv)
outputting video to an external display; and (v)
capturing and recording the sampled data streams
and born-digital video to file.
DarwiinRemote, akawiiremote, and the Max
application manage the connectivity into the com-
puter.3 The second function of the patch involves
randomly selecting files based on the movements of
the performers. As the performers’ bodies shift, the
signal spikes in response to the movement, and the
spikes trigger the selection of videos and still image
files.4 The third operation of the performance patch
transforms the content by manipulating the opacity,
pixel order, and video playback rate; the sensor data
controls the amount and frequency of these manip-
ulations. The processed video is then sent out the
video port on the computer for projection as the
backdrop of the performance.
An example of these three operations can be seen
in Fig. 5. The data, captured during a performance
with the orthotic device created by the team study-
ing Rickets, is presented as a graph (Fig. 5A) and
requires no understanding or knowledge about its
source or what it represents. It is necessary to isolate
the blending function and deconstruct the perfor-
mance in order to understand how the sensor place-
ment as well as the x, y, and z data-streams impacted
the blending effect in the visual backdrop.
Visualizing the impact from numbers alone is chal-
lenging, especially when only subsets are used and
Fig. 2 ‘Jiminy Rickets’ design artefacts (Coartney and Wiesner, 2007)
J. S. Coartney and S. L. Wiesner
156 Literary and Linguistic Computing, Vol. 24, No. 2, 2009
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
these values normalized. Therefore, in order to
represent the impact of changing values on the
overall composition, the images shown in Fig. 5B–
D display the results from three different blend
values.
The final process, the capture and recording of
the sensor data stream, sample rate, and video
output, is not a necessary component of the perfor-
mance, but it is integral to this project. It is the
capture and preservation of the data that allows
Fig. 4 A screen capture of the December 2007 Walk Don’t Run performance patch used to dynamically generate the real
time data visualization. Cycling74 Max/MSP Version 4.6.3, Jitter Version 1.6.3, Mac 0S X Version 10.4.x (Coartney and
Wiesner, 2007)
A     B C
Fig. 3 Sensor technologies including (A) Nintendo Wiimote (Coartney and Wiesner), (B) Newton Apple (Coartney
and Wiesner, 2007) and (C) force strip (Coartney and Wiesner, 2007)
Performance as digital text
Literary and Linguistic Computing, Vol. 24, No. 2, 2009 157
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
for the study, analysis, and recreation of the video as
a performic element. Further, by sampling the data-
streams and capturing performance data, we are
able to analyse existing data for a particular perfor-
mance, deconstruct/reconstruct original performic
events, and create new ones.
Further, with a nod to Naugle, by making the
artefacts accessible to artists we can enable creativ-
ity, which in turn further supports our research. For
example, from ARTeFACT Alpha (Walk Don’t Run)
to ARTeFACT Beta (For Natalie) there was not only
the creative stimulus for the choreographer, but also
a unique example of movement patterns shared
across works (Fig. 6A–C).5 Further, collecting
these artefacts allows us to problematize yet again
the use of preservation mechanisms such as motion
capture and labanotation in dance research, as the
movement was so difficult to notate that the chor-
eographer was reduced to capturing only a few
steps, and resorted to developing her own system
of signs and verbalization to describe the rest, a
common method of describing dance, a method
without a ubiquitous lexicon.6
As demonstrated by the images above, by captur-
ing and preserving visual artefacts we are able to see
the visible traces of the movement patterns. Further,
as we move into the next phases of the project we
will not only be able to use the choreographers’
work against the data to see the true mechanics of
the movement, we will also be able to see traces
between movement and data. Thus, by making the
preserved artefacts ‘accessible’ to researchers we are
taking steps, however small, towards the future
development of exploitable metadata, automatic
pattern recognition, and even feature-based tagging
of moving image.
2 Conclusion
The task of capturing and preserving a performance
is challenging in and of itself without adding the
0
50
100
150
200
250
300 1 Samples (10.25 per second)
A
B C D
0.28Blend Value: 0.70 0.43
Wiimote "X" data 
Wiimote "Y" data 
Wiimote "Z" data 
Fig. 5 The graph (A) plots the x, y, and z numeric values from the Wiimote as stored in the computer. Captured data
samples range in value from 0 to 255 with a sample arte of once every 80 ms. Created by normalizing and processing the
data from the Wiimote’s ‘y’ axis, individual video frames (B, C, D) demonstrate the blending of a still image and a video
(Coartney and Wiesner, 2007; Bryant et al., 2007)
J. S. Coartney and S. L. Wiesner
158 Literary and Linguistic Computing, Vol. 24, No. 2, 2009
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
complexity of performance elements that are created
in real time. One might question the value of col-
lecting and preserving artefacts for all elements sur-
rounding a dance. Dance is, after all, ephemeral, and
in fact, mo-cap guru Eshkar has stated, ‘Of course
you could reuse the files but why would you want
to?’ (quoted in Naugle, 2001, p. 77). So why bother
preserving the various elements?
As technological advances continue, the rules and
limits surrounding publication and distribution of
knowledge will change and we perceive a future in
which time-based media and the display of non-
linear information will not be the challenge it is
today (Kholief, 2003; Reichert, 2007). Access to
filmed and online entertainment as well as console
and online video games will impact scholarship and
research in ways we can only imagine. Studying,
understanding, and exploiting these new sets of
tools will allow us to more fully integrate science,
technology, and the arts and to capture the signals
and begin to interpret the secret messages generated
as part of this media-rich experience.
Notes
1 Neither can a written text give a comprehensive repre-
sentation of a work, for as much as we in the discipline
would like to believe that we focus on movement ele-
ments, research has shown that often do so only in an
effort to substantiate our subjective realization of theme
(Wiesner, 2007).
2 Movement disabilities included stroke-induced ‘drop
foot’ and paralysis, Cerebral Palsy hypertonia, knock-
A B
C
Fig. 6 The challenge of manoeuvring while wearing the orthotic device (Coartney and Wiesner, 2007) (A) are described
by the choreographer (Coartney and Wiesner, 2007) (B) and translated into derivative movements performed in For
Natalie (C)
Performance as digital text
Literary and Linguistic Computing, Vol. 24, No. 2, 2009 159
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
knees as a result of Rickets, leg-length discrepancy, and
locked knee syndrome).
3 The Wiimote, a Bluetooth enabled device with built-in
accelerometers and an optical sensor, synchronizes with
the Macintosh using, DarwiinRemote, open source
software found on the sourceforge website, www.sour
ceforge.net. A second piece of software, aka.wiiremote
currently available at http://www.iamas.ac.jp/aka/
max/, is an external object built specifically for Max/
MSP/Jitter by Masayuki Akmatsu and it feeds the
Wiimote data stream into the performance software
patch.
4 The source data for the performance consisted of fifty-
one movie and still image files totalling 200 MB. The
videos and still images were extrapolated from the pro-
ject documentation that occurred throughout the
semester. The resulting video, displayed as a backdrop
during the production, was a dynamically generated
visualization of the process of designing and creating
the orthotic devices worn in the performance.
5 In addition to her study of the digital artefacts gener-
ated by the engineering class students, the choreogra-
pher used the devices themselves (actually wearing
them to choreograph). This forced her to work within
the limitations of the devices, inhibiting her level of
abstraction, thus causing her to choose movement simi-
lar to those of the students, especially in the case of the
Rickets device. Still, although closely associated with
project Alpha (indeed, almost a derivative), according
to the FRBR principles, For Natalie is not an expression,
but a new ‘work’ replete with its own collection of
artefacts, such as the choreographers notes, interviews
with the choreographer, film of rehearsals and perfor-
mance, programs, a research paper, movement analysis,
and labanotation).
6 Admittedly, an experienced notator may be able to
capture the movements; however, this level of expertise
is difficult to obtain and, sadly, few notators of such
expertise exist.
References
Adshead-Lansdale, J. (ed.) (1999). Dancing Texts:
Intertextuality and Interpretation. London: Dance
Books.
Bryant, D., Lenz, S., Manaktala, R., and Mason, K.
(2007). Jiminy Ricketts. Still Images: Digital. Project
collection (UVA).
Coartney, J. and Wiesner, S. (2007). ARTeFACT. Still
Images: Digital. Project collection (UVA).
Dance Heritage and Coalition (2006). Documenting
Dance: A Practical Guide. Washington, DC: Dance
Heritage Coalition.
Goellner, E. W. and Murphy, J. S. (1995). Bodies of the
Text. New Brunswick, NJ: Rutgers University Press.
Kholief, M., Maly, K., and Shen, S. (2003). Event-based
Retrieval from a Digital Library Containing Medical
Streams, Proceedings of the 2003 Joint Conference on
Digital Libraries (Online). http://ieeexplore.ieee.org/
Xplore/login.jsp?url¼/iel5/8569/27127/01204867.pdf
(accessed 31 March 2008).
Naugle, L. (2001). Reinterpreting choreography: motion
capture data as historical information. In Society of
Dance History Scholars Proceedings 2001,
24th Conference. Birmingham: SDHS.
New York Public Library for the Performing Arts,
Jerome Robbins Dance Division (2005). Report from
Working Group 4. Dance Documentation Needs
Analysis Meeting 2.
Nichols, M. M. (1997). Art and artifact: the digital option,
a case study of the ‘Il Papa’ manuscript. In Society of
Dance History Scholars Proceedings 1997, 20th
Conference. Birmingham: SDHS.
Reichert, L. (2007). Intelligent Library System Goes Live
as Satellite Data Streams in Real-Time (Online).
http://www.lockheedmartin.com/news/press_releases/
2001/IntelligentLibrarySystemGoesLiveAsS.html
(accessed 31 March 2008).
Stalnaker, R. (2008). For NatalieVideo: DVD. Personal
collection (slide).
Wiesner, S. L. (2007). Framing Dance Writing: A Corpus
Linguistics Approach. Ph.D. thesis, University of Surrey,
Guildford, Surrey.
J. S. Coartney and S. L. Wiesner
160 Literary and Linguistic Computing, Vol. 24, No. 2, 2009
 at U
B Leipzig-Zw
st G
eistes - U
nd on January 17, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
