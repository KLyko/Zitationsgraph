Linguistic steganography with
knowledge-poor paraphrase
generation
............................................................................................................................................................
Katia Lida Kermanidis
Department of Informatics, Ionian University, Greece
.......................................................................................................................................
Abstract
Paraphrasing is very useful for many applications that normally involve deep
linguistic alterations of a sentence, like summarization, textual entailment and
question answering, and usually require sophisticated external resources,
pre-processing, and semantic thesauri. This article presents a methodology for
generating shallow linguistic alterations of Modern Greek sentences making use
of only a low-resource chunker and taking advantage of the freedom in phrase
ordering of the language. A statistical significance testing process is applied for
extracting â€˜swappableâ€™ phrase bigrams. A supervised filtering phase follows, which
helps to remove erroneous paraphrasing schemata, taking into account the con-
text in which the alteration is to take place. Unlike most previous approaches to
paraphrasing, the proposed process is knowledge-poor (and thus quite easily
portable to other languages with a syntactic structure similar to Modern
Greek), robust (applicable to any type of text), domain independent, and leads
to the generation of a significant number of paraphrases, by allowing the appli-
cation of more than one syntactic alterations per sentence. The significance of the
automatically generated paraphrases is shown by their application in hiding
secret information underneath a cover text in a steganographic communication
channel. For this purpose, they need not be sophisticated linguistic alterations,
but grammatically correct and significant in number, to ensure security. A ste-
ganographic security and capacity analysis of the presented implementation, as
well as an explanatory description of the trade-off between them, is included to
show the usefulness and the practical value of the methodology.
.................................................................................................................................................................................
1 Introduction
Numerous Natural Language Processing applica-
tions require a component that, given a sentence,
reformulates it (changes its syntactic structure
and/or vocabulary), but preserves its meaning. In
other words, it generates paraphrases of the original
sentence. Example 1 shows paraphrase generation
for a Modern Greek (MG) sentence using a different
set of words, while in example 2 paraphrasing is
achieved through syntactic restructuring.
(1)  0!  0 Å’	
  
0"
(Iâ€™ll go for a walk until it gets dark)
 "
â€“! Å’	
  Å’" o â€“o&
(Iâ€™ll walk until the sun sets)
(2) Å’
 	"& 0 o oo0
o  Å’
Å’"	o
(I went by the dentistâ€™s yesterday
for a check-up)
V"& Å’
  Å’ Å’"	o 0 o
oo0
o
Paraphrasing is an important indicator of lin-
guistic competence in first- and second-language
learning (Milicevic, 2008), it provides significant
Correspondence:
Katia Kermanidis,
Department of Informatics,
Ionian University, 7 Tsirigoti
Sq., 49100 Corfu, Greece.
E-mail:
kerman@ionio.gr
Literary and Linguistic Computing, Vol. 26, No. 4, 2011.  The Author 2011. Published by Oxford University Press on
behalf of ALLC. All rights reserved. For Permissions, please email: journals.permissions@oup.com
417
doi:10.1093/llc/fqr026 Advance Access published on 30 May 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
resources for authoring support (Okamoto, 2003;
Barreiro, 2009), it is essential for text summariza-
tion (Brockett and Dolan, 2005), for text realization
in natural language generation (Harbusch et al.,
2007), as well as for question answering (Duclaye
et al., 2003), machine translation (Nakov, 2008),
textual entailment, and semantic inference
(Bar-Haim et al., 2009).
The aforementioned applications usually make
use of automatically extracted paraphrases that are
intricate linguistic alterations of an original sen-
tence, requiring sophisticated tools and resources
that are not available for many languages. The ex-
tracted paraphrases are limited in number and the
necessary tools are usually domain-specific and not
particularly robust, i.e. they have limited coverage
and can only be applied to text that is restricted in
structure and domain.
The present work describes the process of auto-
matically generating shallow MG paraphrases, and
then, of using them to enable steganographic com-
munication between two parties that wish to ex-
change secret information. The bits of the secret
message are embedded within a cover text in an
unremarkable way that does not arouse an eaves-
dropperâ€™s suspicion to the existence of hidden in-
formation. This application defines the two primary
goals of the presented approach. The first goal is to
produce as many correct paraphrases as possible for
an original sentence. Steganographic security de-
pends to a large extent on the number and the
grammaticality of the paraphrases of each cover
text sentence. Unlike previous work, where each
paraphrasing rule may be applied once to a sentence
(Meral et al., 2007), the transformations proposed
in the present approach may be applied multiple
times (i.e. in multiple positions) to a sentence.
Thereby, the number of extracted paraphrases in-
creases. Security in steganography is always in a
trade-off relation to steganographic capacity, i.e.
the amount of secret information that may be
embedded into the cover medium. An analysis of
steganographic security and capacity of the pro-
posed approach is included at the end of the article.
The second goal is to employ as limited linguistic
resources as possible. This will first allow the port-
ability of the proposed methodology to other
languages that share certain syntactic properties
with MG (e.g. Hungarian), and that are not neces-
sarily equipped with sophisticated linguistic re-
sources. Also, it will ensure robustness and
domain independence (the proposed alterations
are applicable to any MG text, regardless of its
domain, genre or stylistics). The paraphrases need
not be sophisticated syntactic or semantic alter-
ations that presuppose the availability of high-level
linguistic resources. The methodology requires a
morphological case tagger (in the experiments pre-
sented here the corpus is manually tagged with mor-
phological information, including the case), a
phrase chunker that utilizes limited resources,
a list of the most frequent copular MG verbs, and
a list of the most common relative MG adverbs.
Even the most elementary transformation is ad-
equate for hiding secret information, as has been
shown in previous work (Kermanidis and Magkos,
2009), unlike previous approaches that rely on more
sophisticated syntactic alterations (Meral et al.,
2009; Chang and Clark, 2010).
To present the paraphrasing process briefly, the
proposed methodology is a combination of two
phases: a statistical process for generating an initial
set of paraphrases and a filter that helps to remove
erroneous (noisy) paraphrases. In other words, a
statistical significance testing process is responsible
for generating pairs of consecutive phrases (chunks)
that are swappable, i.e. they are permitted to swap
positions. Swappability is determined based on the
phrasesâ€™ co-occurrence statistics. Due to the low re-
source policy employed, the resulting set of chunk
pairs is noisy and contains pairs that often lead to
syntactically incorrect output when swapped. For
this reason, a filtering phase follows that helps
remove such error-prone pairs. Filtering is per-
formed using supervised learning [a support
vector machines (SVM) classifier], which identifies
erroneous swaps by taking into account the context
they appear in. To the authorâ€™s knowledge, this is
the first time a (partly) unsupervised approach to
generating MG paraphrases is proposed.
The next section presents previous approaches
to paraphrasing. Section 3 describes the MG
corpus used in the presented experiments, its pre-
processing, the paraphrase generation and filtering
K. L. Kermanidis
418 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
process, as well as its evaluation. Section 4 presents a
literature review on linguistic steganography, and
describes the proposed message embedding and ex-
traction process, including a discussion on security
and capacity aspects. The article concludes in
Section 5.
2 Paraphrasing: Related Research
Automatic paraphrasing entails paraphrase gener-
ation, i.e. the realization of a new sentence to ex-
press the meaning of another, and/or paraphrase
identification (or acquisition), i.e. given two sen-
tences, the classification of one as an (in)valid para-
phrase of the other. Approaches to paraphrase
generation vary from the application of hand-
crafted syntactic rules (Meral et al., 2007) to
dictionary-based synonym replacement techniques
(Bolshakov, 2004). Paraphrase acquisition focuses
on empirical methods to detect synonymous (or
near-synonymous) sentences, resulting in resources
that allow for paraphrase generation, such as the
empirical construction of finite state automata
that represent word lattices with synonymous arcs
(Pang et al., 2003), the use of statistical machine
translation techniques (like word alignment on
monolingual parallel corpora to build parallel inter-
changeable word/phrase pairs) (Quirk et al., 2004),
and using shared named entity markers in sentences
of different articles to identify parallel utterances
and then extract patterns of dependency relations
from them (Shinyama et al., 2002). Subsumption
of two syntactic dependency graphs is checked, re-
vealing equivalent graphs, in the work by Rus et al.
(2008). Word lattices depicting patterns from clus-
ters of structurally similar sentences are detected
with multiple sequence alignment in the work
described by Barzilay and Lee (2003). Viewing para-
phrase identification as a tagging task, supervised
machine learning (Kozareva and Montoyo, 2006)
has also been proposed. In the series of PASCAL
Recognizing Textual Entailment Challenges [the
last of which is described in Bentivogli et al.
(2009)] teams compete in implementing systems
that perform semantic inference, i.e. given one
sentence, they attempt to decide upon the meaning
of another.
As already mentioned, most previous approaches
aim at producing paraphrases that are relatively
deep alterations of the original sentence, taking
full advantage of their available resource potential,
without worrying about the number of generated
paraphrases. The focus of the present approach
shifts to coverage, to the ability to apply the pro-
posed shallow syntactic transformations to any MG
text, to the fairly easy applicability of the method-
ology to languages that are not equipped with
sophisticated resources and tools, and to the
number of extracted paraphrases. As already men-
tioned the only required tools are a case tagger, a
low-resource chunker, a list of the most frequent
MG copular verbs, and a list of the most common
MG relative adverbs. Resources like parallel corpora,
semantic thesauri, syntactic parsers, etc. are not
necessary.
3 Syntactic Transformations
This section describes in detail the process of gen-
erating shallow MG paraphrases. Certain linguistic
properties of the language in question need to
be presented first, as well as the corpus used and
the shallow pre-processing tools that were applied
to it.
3.1 Modern Greek and languages with
similar syntax
A core aspect of the current work is the language in
question. MG is highly inflectional. While the pos-
ition of the words within a phrase is relatively strict,
the rich morphology allows for a large degree of
freedom in the ordering of the phrases within a sen-
tence. This phrase ordering freedom is a significant
property of the language, and enables paraphrase
generation merely by permutating the phrase order.
[G 
0"] ["0"] [" "0"&] [	
â€“].
[The bank] [lends] [to clients] [money]
In the English translation, only very limited
re-ordering of the phrases is permitted. The two
objects ([to clients] and [money]) may swap
places, but any other permutation leads to either
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 419
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
an ungrammatical or an unnatural sentence.
The English language syntax follows to a large
extent the subjectâ€“verbâ€“object (SVO) order.
However, all the permutations of the phrases in
the Greek example above result in grammatically
correct sentences, which are semantically identical
to the original sentence. MG does not follow the
SVO order. Subjectâ€“verb and verbâ€“object depen-
dencies are determined by the morphology of the
participating constituents rather than their position
in the sentence. Certain permutations (see next ex-
ample) may not be common in everyday language,
due to their stylistic properties (i.e. they are
â€˜poeticâ€™ or â€˜theatricalâ€™), but they remain perfectly
grammatical.
[" "0"&] [	
â€“] ["0"] [ 
0"].
Several languages are similar to MG regarding
this phrase ordering freedom, like Hungarian
(Kornai, 1992), Urdu (Ali and Hussain, 2010),
Bengali (Ekbal and Bandyopadhyay, 2009),
Arrernte (Levinson and Wilkins, 2006). A signifi-
cant number of these languages is not adequately
equipped with linguistic resources (Ekbal and
Bandyopadhyay, 2009), thus increasing the import-
ance of the knowledge-poor policy and the relatively
easy portability of the proposed methodology.
3.2 Corpus and pre-processing
The ILSP/ELEFTHEROTYPIA corpus (Hatzigeorgiu
et al., 2000) used in the experiments consists of
5,244 sentences, is manually annotated with mor-
phological information, and balanced in genre.
Phrase structure information is obtained automat-
ically by the chunker described in Stamatatos et al.
(2000). During chunking, noun (NP), verb (VP),
prepositional (PP), adverbial phrases (ADP), and
conjunctions (CON) are detected via multi-pass
parsing. The chunker exploits minimal linguistic re-
sources: a keyword lexicon containing 450 closed-
class words (articles, prepositions, etc.) and a lexi-
con of 300 of the most common word suffixes in
MG. The chunker identifies basic phrase construc-
tions during the first passes (e.g. adjectiveâ€“nouns,
articleâ€“nouns), and combines smaller phrases into
longer ones in later passes (e.g. coordination, inclu-
sion of genitive modifiers, compound phrases).
Certain features of the extracted chunks need to
be noted:
1 Chunks are non-overlapping, i.e. no chunk con-
tains whole or part of other chunks.
2 Nominal modifiers in the genitive case are
included in the same phrase with the main
noun they modify.
3 Base nouns joined by a coordinating CON are
grouped into one phrase.
3.3 Hypothesis testing
After splitting the corpus sentences into
non-overlapping phrases, phrase types are identified
by discarding content words from the phrases, and
keeping only lexicosyntactic information that has an
impact on the position of the phrases in the sen-
tence. For NP types this information is the gram-
matical case of their headword. The headword is the
noun in the nominative or accusative case. If there is
no noun, it is the adjective, numeral or pronoun in
this order, else the first phrase element. VP types are
distinguished by the verb voice, by the CON intro-
ducing them (if any), and by their copularity
(whether they are copular or not). Copular verbs
denote a trait, a property, like "0 (to be) and
0o (to become). PP types are distinguished
by the preposition introducing them, CON types
by their CON-type (coordinating or subordinating),
and ADP types are distinguished by their type (rela-
tive adverb or not). Copular verbs and relative ad-
verbs are limited in number and easily identified. A
total of 156 phrase types were formed.
Next, the statistical significance of the co-
occurrence of two phrase types is measured using
hypothesis testing: the t-test, the log likelihood ratio
(LLR), the chi-squared metric (	2), and pointwise
mutual information (MI) metrics have been experi-
mented with. A detailed description of these metrics
and their comparative evaluation can be found
in many sources (Manning and Schuetze, 1999;
Seretan, 2008). Phrase type pairs that occur in
both orderings ([TYPE1][TYPE2] and [TYPE2]
[TYPE1]) among the top results with the highest
rank (i.e. among the highest statistical significance
values) are selected. These are considered permis-
sible phrase swaps, as both orderings show signifi-
cant correlation between the phrases forming them.
K. L. Kermanidis
420 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
Table 1 shows the size of the set of selected phrase
pairs for every statistical significance metric (only
one of the two orderings is counted for every
pair), and various values for the number of the
N-best (top) results. For all N-values, statistical sig-
nificance proved to be well above the threshold for 
level 0.05. Table 2 shows the swap pairs for NÂ¼ 100.
The process focuses on consecutive chunks in
order to minimize the possibility of an erroneous
swap: the longer the distance between the phrases to
be swapped, the more probable it is for long-
distance syntactic dependencies to be affected, and
therefore for syntactic errors to appear. Long-
distance phrase swaps would be safer if the meth-
odology employed linguistic tools for deep
processing.
Swap pairs that are a priori known to be incap-
able of producing legitimate swaps are removed
from the sets ([Type][#], [Type][CON-
coordinating], [Type][CON-subordinating], and
their symmetrical pairs). â€˜#â€™ denotes end of sentence
(the low-resources chunker sometimes groups
punctuation marks into phrases).
For the remaining pairs, in case one is detected in
an input sentence, the two phrases are swapped,
and, thereby, a paraphrase is produced. The average
number of swaps that are permitted per sentence for
each phrase swap set in Table 1 is shown in Fig. 1. If
more than one phrase swaps are applicable at dif-
ferent positions in an input sentence, all possible
combinations of swaps are performed, and all re-
spective paraphrases are produced, forming the ini-
tial pool of paraphrases. Figure 2 shows the
frequency distribution of the initial pool size for
the top 100 t-test metric, i.e. 482 sentences have 0
paraphrases, 1,468 have 1â€“2 paraphrases, etc.
Then, two native speakers judged 882 randomly
selected sentences and their produced paraphrases,
according to grammaticality. The judgment process
was blind, i.e. the experts were not familiar with the
original sentence. They were simply shown a set of
sentences and asked to decide whether they were
grammatical, or they required a phrase swap to
become grammatical.
It is possible for a swap to result in a grammat-
ically correct, but semantically different sentence
compared to the initial one. This is not a problem
in the present approach, as the cover text meaning
itself is not important. Interexpert agreement ex-
ceeded 94% using the  statistic. The percentage
of paraphrases (sentences) that required one or
more manual phrase swaps from the human
judges in order to become grammatical is shown
in Fig. 3 for every swap set. It should be
noted that an average of 6% of the reported errors
were on the original sentences, an indication of
an upper bound of the performance of the specific
task.
MI, due to its relation to Information Theory,
returns a more diverse set of swap pairs, i.e. a set
that contains â€˜exclusiveâ€™ (â€˜surprisingâ€™, not very fre-
quent) phrase types, that are not included (or
included scarcely) in the sets returned by the other
metrics. Such phrase types are relative ADPs, geni-
tive NPs, unusual PPs (e.g. PPs introduced by the
preposition !&â€”until). This set leads to a small
average number of swaps per sentence, and a high
error rate. T-test returns an extensive set of swap
pairs that consist of more frequent (usual) phrase
types and results in the smallest error rate. The use
of the t-test for testing the significance of word co-
occurrence has been contested, due to its assump-
tion that the data is normally distributed (Seretan,
2008). The good results in the current approach are
attributed to the fact that the statistical significance
of phrase typesâ€™ rather than wordsâ€™ co-occurrence is
tested, and the distribution of phrase types is not as
heavily tailed as the Zipfian distribution (the distri-
bution of words), due to the â€˜de-lexicalisationâ€™
process.
A set of nine manually created rules that govern
bigram and trigram chunk swaps has been applied
to the same data set (Kermanidis and
Table 1 Swap set size for every metric
Size of phrase swap set
Top 50 Top 100 Top 200 Top 300
t-test 19 21 24 27
LLR 11 15 18 19
	2 12 20 25 29
LI 16 26 32 36
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 421
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
Table 2 The swap pair sets for every metric and top 100 statistical significance values
LLR t-test 	2 LI
1 [NPacc][NPacc] [NPacc][NPacc] [NPacc][NPacc] [NPacc][NPacc]
2 [NPacc][VPact] [NPacc][NPnom] [NPacc][VPact] [NPacc][NPnom]
3 [NPacc][VPpass] [NPacc][VPact] [NPacc][VPpass] [NPacc][VPact]
4 [NPacc][PP] [NPacc][PP0] [NPacc][PP] [NPacc][VPpass]
5 [NPacc][PP"] [NPacc][PP"] [NPacc][PP"] [NPacc][VPcop]
6 [NPacc][ADP] [NPacc][PP"] [NPacc][PP"] [NPacc][PP"]
7 [NPacc][VPact] [NPacc][ADP] [NPacc][ADP] [NPacc][ADP]
8 [NPnom][NPnom] [NPacc][VPact] [NPnom][NPnom] [NPacc][0VPact]
9 [NPnom][VPact] [NPnom][NPnom] [NPnom][VPact] [NPgen][VPcop]
10 [NPnom][VPpass] [NPnom][VPact] [NPnom][VPpass] [NPacc][NPnom]
11 [NPnom][PP0] [NPnom][VPpass] [NPnom][VPcop] [NPnom][PP"]
12 [NPnom][PP"] [NPnom][VPcop] [NPnom][ADP] [NPnom][ADPrel]
13 [NPnom][ADP] [NPnom][PP0] [VPact][VPact] [NPnom][VPact]
14 [VPact][PP"] [NPnom][PP"] [VPact][VPpass] [VPact][VPact]
15 [VPact][ADP] [NPnom][ADP] [VPact][PP] [VPact][VPpass]
16 [VPact][PP"] [VPact][PP"] [VPact][PP!&]
17 [VPact][ADP] [VPact][ADP] [VPact][PP0]
18 [VPpass][PP"] [VPpass][VPpass] [VPact][ADPrel]
19 [VPpass][ADP] [VPpass][ADP] [VPpass][VPpass]
20 [PP][PP"] [VPact][VPact] [PP0][PP"]
21 [PP"][ADP] [PP0][VPpass]
22 [PP][PP]
23 [PP][ADP]
24 [VP"][ADPrel]
25 [VPpass][ADP]
26 [0VPact][ADP]
The words appearing are  (for),  (to), " (with), " (in), 0 (that), 0 (from), 0 (against), !& (until). act, pass, nom, acc,
cop, rel, c and s stand for active voice, passive voice, nominative case, accusative case, copular verb, relative adverb, coordinating
conjunction, and subordinating conjunction, respectively.
0
1
2
3
4
5
6
Top50 Top100 Top200 Top300
A
vg
 n
r o
f s
w
ap
s/
se
nt
en
ce
t-test
LLR
X2
MI
Fig. 1 Applicability of the phrase swap pairs
K. L. Kermanidis
422 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
Magkos, 2009), and the authors reported an error
rate of 8.2%. The rules are chunk swaps that repre-
sent shallow versions of subjectâ€“verb swapping,
verbâ€“secondary clause of result swapping, coordi-
nated phrases swapping, swapping of an ADP with
its preceding phrase, and verbâ€“PP swapping. They
are unification rules, i.e. morphological constraints
determine their applicability. Attempting to extract
â€˜swappableâ€™ phrase pairs statistically leads to a
higher error rate, compared to the one achieved
by the limited set of strict rules. However, at the
same time, the number of generated paraphrases
in the former case is significantly greater (there is
a 15% increase in the number of generated para-
phrases compared to the hand-crafted rules
approach).
A significant part of the errors is attributed to the
automatic nature and the low level of the chunking
process: erroneous phrase splitting, incorrect attach-
ment of punctuation marks, and the inability to
identify certain relative, adverbial, and idiomatic ex-
pressions, and to solve PP attachment ambiguities
and subordination dependencies lead to swapping
errors that would have been avoided by applying
more sophisticated parsing.
3.4 Filtering
To reduce the error rate, the extracted swap sets
undergo a filtering process, where erroneous swap
pairs are learned [pairs are classified as (in)valid]
and withdrawn from the final pair sets. The pos-
itions of possible phrase swaps in the input sen-
tences are identified according to the t-test swap
set from the previous section. The swap set for the
top 100 results was selected, as its error rate turned
out to be significantly lower than that of the top 200
and top 300 swap sets, and the average number of
paraphrases it returned higher than the top fifty set.
A learning vector is created for every input sen-
tence and each swap position. The features forming
the vector encode syntactic information for the
phrase right before the swap position, as well as
25,00%
27,00%
29,00%
31,00%
33,00%
35,00%
37,00%
39,00%
41,00%
Top50 Top100 Top200 Top300
Er
ro
r 
ra
te
t-test
LLR
X2
ÎœÎ™
Fig. 3 Error rate for every swap set
0
200
400
600
800
1000
1200
1400
1600
0 1-2 3-5 6-10 11-20 21-30 31-50 >50
Bins of initial pool sizes
Nu
m
be
r 
o
f s
en
te
n
ce
s
Fig. 2 Frequency distribution of the initial pool size for
the Top 100 t-test metric
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 423
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
two phrases to the left and two phrases to the right
(a total of five phrases). Thereby, context informa-
tion is taken into account. So even though the visi-
bility of the swaps is limited to only two consecutive
chunks, the filtering phase broadens the focus on
the context surrounding the swap. Each of the five
phrases is represented through a set of six features,
shown in Table 3.
The first feature for every phrase is the phrase
category (NP, VP, PP, etc.). Case is a character
denoting the case of an NP headword. Case is de-
cisive for several cases of swapping: a qualitative
evaluation revealed that, while [NPnom][VPpass]
is usually â€˜swappableâ€™, [NPacc][VPpass] usually is
not. Morph is a three-letter code denoting whether
an NP contains a definite or indefinite article and its
case. The (in)definitiveness of an NP affects the ac-
curacy of swaps containing NPs. The fourth feature
varies according to the phrase category. For NPs it is
the type of pronoun appearing in them, if any. It is
the first word (non-verb) introducing a VP, the
preposition introducing a PP, and the CON or the
adverb in a CON and an ADP, respectively. The fifth
feature is binary and encodes whether there is an
element in the genitive case in an NP, or a copular
verb in a VP. The presence of a genitive element is
often decisive for the accuracy of swaps containing
NPs. Finally, num is the number of tokens (words)
within a CON or an ADP. This feature is very im-
portant, as a one-word ADP phrase usually denotes
manner and a swap with its preceding phrase is per-
missible, while a multi-word ADP phrase very often
does not.
In previous supervised learning approaches to
paraphrase identification (Kozareva and Montoyo,
2006), a learning example represents a pair of sen-
tences through a set of features that denote
lexico-semantic similarity between the two sen-
tences, like shared word sequences, word similarity,
etc. The goal is to decide whether one of the two
sentences is a paraphrase of the other. In the current
approach, the presented data set consists of learning
examples, each one representing a single sentence.
Features encode morphosyntactic information re-
garding the context surrounding a specific position
of the sentence. There is a different learning ex-
ample for each position. The goal is to decide
whether the two phrases surrounding the given pos-
ition may or may not be swapped. Lexico-semantic
features like the ones mentioned previously are out
of the scope of the present methodology and not
abiding by the low resource policy.
Native speakers have manually annotated the in-
stances (vectors), corresponding to the 882 original
sentences (5,104 instances) already used for the
evaluation of the statistical significance testing pro-
cess. A SVMs classifier (with a first degree polyno-
mial kernel function, and the sequential minimal
optimization algorithm for training) was trained
to classify instances using 10-fold cross-validation.
SVMs were selected because they are known to cope
well with high data sparseness and multiple attribute
problems, both valid in the present data set.
Classification performance reached 82% precision
and 86.2% recall. Kozareva and Montoyo (2006)
(even though no direct comparison would be mean-
ingful as their methodology and data set are very
different) report 100% precision and 66.49% recall
for knowledge-rich paraphrase identification with
an SVMs classifier.
The correlation of each swap pair with the target
class was estimated next. The swap pairs that appear
more frequently in negative (invalid paraphrase)
than in positive instances were removed from the
final swap set (seven in number). Table 4 shows the
percentage of appearance of each of the t-test swap
pairs with the positive and negative class. The
removed pairs are indicated in bold. Figure 4 depicts
the full process of paraphrasing described so far.
The reduced swap set was evaluated against a
held-out test set (100 new corpus sentences, not
included in the training data of the filtering phase)
and reached an error rate of 17.2%. Against the
882-sentence training set, the error rate dropped
Table 3 The features of the learning vector
NP VP PP CON/ADP
1 NP VP PP CON/ADP
2 Case â€“ â€“ â€“
3 Morph â€“ â€“ â€“
4 Pronoun in NP First word Preposition First word
5 Genitive element in NP Copular verb â€“ â€“
6 â€“ â€“ â€“ Num
K. L. Kermanidis
424 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
to 13.8%. Given the â€˜knowledge povertyâ€™, the results
are satisfactory when compared to those of
approaches that utilize sophisticated resources
(Meral et al., 2007; Chang and Clark, 2010), which
report an average error rate of 12.7% on the applied
rules, and an error rate varying from 0 to 32.3%
(depending on the value of n and the context size)
when paraphrasing n-gram phrases, respectively.
Table 5 shows the results for all approaches that
make use of the same dataset, and therefore allow
for direct comparison.
The filtering process helps to broaden the focus
on the context surrounding the swap position. The
context is very important when trying to decide
upon a permissible swap. In the following example
the fact that the phrase before the swap position (*)
is an active VP (VP1) links the following NP
strongly with it, not allowing the swap. On several
occasions, however, a swap between an accusative
NP and a VP is permissible.
. . .[0] [o] VP1[Å’	"] NP[0] *
VP2["0. . .] . . .
. . .[that] [what] VP1[has] NP[importance]
VP2[is. . .] . . .
(. . .whatâ€™s important is. . .)
It is interesting to study the pairs that tend to lead
to correct vs. incorrect swaps. [PP] (PP intro-
duced by the preposition â€”for) is usually at-
tached to the sentence verb, and so may almost
always be swapped with the phrase preceding it,
while [PP"] (a PP introduced by the preposition
"â€”to) is more problematic. ADPs may usually be
swapped with preceding NPs, but things get more
complicated when they are preceded by a VP.
Certain secondary clauses (e.g. final clauses
Table 4 Appearance of the co-occurrence of the pair with
the positive and with the negative class
Pair Positive class (%) Negative class (%)
[NPacc][NPacc] 68 32
[NPacc][NPnom] 88 12
[NPacc][VPact] 80 20
[NPacc][PP0] 86 14
[NPacc][PP"] 84 16
[NPacc][PP"] 47 53
[NPacc][ADP] 89 11
[NPacc][VPact] 38 62
[NPnom][NPnom] 72 28
[NPnom][VPact] 89 11
[NPnom][VPpass] 91 9
[NPnom][VPcop] 94 6
[NPnom][PP0] 81 19
[NPnom][PP"] 46 54
[NPnom][ADP] 83 17
[VPact][PP"] 44 56
[VPact][ADP] 42 58
[VPpass][PP"] 58 42
[VPpass][ADP] 47 53
[PP][PP"] 91 9
[PP"][ADP] 52 48
The removed pairs are indicated in bold.
chunking 
raw 
text 
chunked
text
key 
word 
lexicon
suffix 
lexicon
statistical 
significance 
testing 
initial set of 
â€˜swappableâ€™ 
phrase pairs
filtering 
final set of 
â€˜swappableâ€™ 
phrase pairs
context sur-
rounding the 
pairs
Fig. 4 The process of extracting the final reduced set of â€˜swappableâ€™ pairs of consecutive phrases
Table 5 Collective, comparative results
Approach Error
rate
(%)
Manually crafted rules (Kermanidis and Magkos, 2009) 8.2
Initial swap set 29.7
Reduced swap setâ€”training set 13.8
Reduced swap setâ€”held out test set 17.2
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 425
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
introduced by the particle , or relative clauses)
may often be swapped with their preceding main
verb phrase, but not with a preceding NP. The set
of paraphrases generated by the reduced swap set
form the final pool of paraphrases.
4 Application to Steganography
The significance of the produced paraphrases is
shown by their use in linguistic steganography, i.e.
the art of embedding hidden information in unre-
markable cover text in a way that does not arouse an
eavesdropperâ€™s suspicion to the existence of hidden
content underneath the surface message (Atallah et
al., 2000; Cox et al., 2002; Provos and Honeyman,
2003). Linguistic steganography is a relatively new,
interdisciplinary field â€˜at the intersection of natural
language processing and information securityâ€™
(Meral et al., 2009).
4.1 Linguistic steganography: related
research
Previous approaches to the use of natural text as the
cover medium for hiding secret information may be
categorized into two groups. The first group, usually
referred to as text steganography, focuses on alter-
ations made to the physical formatting of the cover
text (Bennett, 2004), like the insertion of spaces,
deliberate orthographical errors, font resizing, line
shifting, creating random or statistical character or
word sequences (Wayner, 2002; Raskin and
Nirenburg, 2003), or taking advantage of the special
features that certain characters contain in some lan-
guages (Gutub and Fattani, 2007). The main draw-
back of these approaches is that they are easily
detectable by human â€˜wardensâ€™ and they are not
robust against attempts to reformat the text. The
second group, referred to as linguistic steganography,
embeds the message to be hidden within the linguis-
tic structure of the cover text, by performing a set of
alterations including synonym substitution, syntac-
tic transformations and semantic transformations
(Topkara et al., 2005).
Synonym substitution replaces words in a sen-
tence with their synonyms (Bolshakov, 2004;
Topkara et al., 2006a,b). Regarding synonym
selection, some approaches employ WordNet syn-
sets (Murphy and Vogel, 2007; Wouters et al., 2007)
and attempt to find the synonym that maximizes the
probability as a substitute for the original word
across all senses requiring a word sense disambigu-
ation tool, while others make use of dictionary-
based synonym lists and apply mixed radix
number encoding and Huffman trees in order to
perform the selection (Winstein, 1998; Bergmair,
2004). Wouters et al. (2007) propose human inter-
vention for synonym selection by the sender, so as
to ensure imperceptibility without having to make
use of a word sense disambiguation tool. Semantic
transformations (Atallah et al., 2002) identify noun
phrases that refer to the same entity (coreferences).
Upon coreference detection, a repeated noun phrase
is replaced by a referring expression (e.g. anaphora).
Again, the needed tools are sophisticated resources
for deep semantic analysis.
Finally, approaches performing syntactic trans-
formations (Meral et al., 2007; Murphy and Vogel,
2007; Kermanidis and Magkos, 2009; Chang and
Clark, 2010), including the one presented in this
article, modify the syntactic structure of a sentence
(while preserving its original meaning). Typical syn-
tactic alterations include activeâ€“passive transform-
ations, extraposition, clefting and they normally
require language-specific parsers. The plural
number of syntactic structures a sentence may
appear in allows for the embedding of information
within the syntactic structure itself. Another syntac-
tic approach, which does not rely on already existing
text, is the use of context-free grammars (CFGs) for
generating text (mimicry) that may hide secret bits
wherever the grammar presents a syntactic ambigu-
ity. The generated text is syntactically correct, as it
has been produced by applying the grammar rules,
but its semantics, discourse structure and style can
be very problematic, making it easily detectable by a
human third party. This is even more the case, if the
grammar is restricted, i.e. it covers only a small set
of syntactic phenomena.
Another set of previous approaches has focused
on natural language watermarking. While in stega-
nography the cover text itself is of no actual import-
ance, in watermarking the cover text is important
and needs to remain intact. Text watermarking is
K. L. Kermanidis
426 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
more intricate than text or linguistic steganography,
as it is challenging to ensure robustness (indestruct-
ibility of the cover text). Shallow (Murphy and
Vogel, 2007) and more elaborate (Topkara et al.,
2006a; Meral et al., 2007) syntactic transformations
have been proposed for hiding secret information
within the cover text in a way that does not allow
the extraction of the hidden message (mark) with-
out destroying the cover text. Synonym substitution
approaches replace a word with a semantically simi-
lar one, in a way that is not safely reversible, i.e. the
initial word cannot be safely identified. Topkara
et al. (2006b) perform synonym substitution using
WordNet to replace the original word with a more
ambiguous synonym, so that the process is irrevers-
ible by a third party without damaging the meaning
of the original text. Atallah et al. (2000) propose the
use of the quadratic residue theory to detect the text
places where meaning-preserving linguistic modifi-
cations should be performed in order to embed the
secret message.
Other approaches make use of machine transla-
tion tools that generate possible translations of a
source sentence and choose one of them to embed
the secret message (Grothoff et al., 2005; Stutsman
et al., 2006). At the orthographical level, Topkara
et al. (2007) insert typographical errors in the
cover text, and take advantage of the correction am-
biguity to insert the secret bits. The tools needed for
this are negligible, but the typos are instantly visible
to a human or a machine warden, presenting thus a
security problem.
Recently, approaches have been focusing also on
the stegoanalystâ€™s end, proposing attacking scenarios
on linguistic steganographic systems. Taskiran et al.
(2006) train two language models, one using cover
(unmodified) and one using steganographic text,
and use the output to train an SVM classifier to
identify text as (un)modified. Chen et al. (2008a)
take advantage of the difference in the statistical
characteristics of correlations between certain
words in normal and stego text in order to distin-
guish between the two text types. Zhi-li et al. (2008)
detect differences between the distributions of
words in the two text types. Chen et al. (2008b)
also use an SVM classifier to classify between mod-
ified and unmodified text by taking into account an
information entropy variable and statistical vari-
ance. Meng et al. (2008) compare the perplexities
of normal and steganographic text that derive from
a stego text language model, and find them very
different.
4.2 Embedding the hidden message
Once the final pool of paraphrases for every sen-
tence in the input (cover) text is formed, a secret
message, i.e. a sequence of bits, is to be embedded
within the cover text in three stages. As the phrase
swaps are bi-directional, one direction is chosen (by
convention, or using a secret symmetric crypto-
graphic key) by the two communicating parties,
and each side of the swap is marked with a 1-bit
value (e.g. â€˜0â€™ marks the left and â€˜1â€™ marks the
right-hand side of a specific swap). A cryptographic
key is a secret bit string shared beforehand between
the two parties. So, for example, if the first bit of the
key equals to â€˜1â€™, this could mean that the left-hand
side of the first phrase pair in the set is marked
with â€˜1â€™.
In the next stage, for every text sentence, the ap-
plicable phrase swaps are selected from the swap set.
If the sentence does not allow for any swap, it re-
mains unchanged, and is not used for information
embedding. If it does, a selection is possible either in
a round-robin fashion, or using the secret symmet-
ric cryptographic key.
In the last stage, a secret bit is embedded as fol-
lows: if the bit to be hidden matches the marking of
the selected applicable swap, the swap is not applied
and the sentence remains unchanged, otherwise it is
applied and the sentence is paraphrased.
4.3 Extracting the hidden message
On the other end, the extractor receives the final
text. Having at his disposal the same swap set, he
is able to identify the swaps that may be applied to
each sentence. Sharing the same secret key, he is able
to select the same swap used in the insertion pro-
cess. For example, reading [NPnom][VPact], and
knowing that this sequence indicates a â€˜0â€™ marking,
he decides on â€˜0â€™ to be the first secret bit. Reading
[VPact][NPnom] would have meant a â€˜1â€™ marking
and he would have decided on â€˜1â€™ to be the first
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 427
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
secret bit. The message insertion/extraction algo-
rithm is shown step-by-step in Figs 5 and 6.
4.4 An example of information hiding
Let the following three sentences constitute the ini-
tial message.
(A) VP[0o] NP["â€“&]
[I become] [an adult]
(B) VP[â€™0"]PP[o "0o "0
o] ADP[	"&]
[we ate][at the Mexican place] [yesterday]
(C) VP[o
0"]
[heâ€™s tired]
Letâ€™s assume the following final swap set:
[VPpass][NP] (1)
[VPact][PP"] (2)
[PP"][ADP] (3)
The applicable swap pairs for the given text are:
For sentence A, pair (1); for sentence B pairs (2) and
(3); and for sentence C no pair. So the final pool of
paraphrases is:
(A1) ["â€“&] [0o]
[B1â€“after swap (3)] [â€™0"][	"&]
[o "0o "0
o]
[B2-after swap (2)] [o "0o "0
o]
[â€™0"][	"&]
Suppose that the hidden message is the bit se-
quence â€˜10â€™. For embedding the secret message, the
marking of the pair that is applicable to the first
sentence is being checked. Assuming that a
[VPpass][ADP] sequence corresponds to swap
marking â€˜0â€™, the two bits donâ€™t match (as the first
bit to be hidden is â€˜1â€™). Therefore, swap (1) is
applied, the paraphrase is activated and the first
sentence to be sent is A1.
Given the secret key, or in a round-robin fashion,
the message sender decides next on one of the two
applicable swap pairs for sentence B. Suppose that
pair (2) is chosen and that, according to this pair, a
[VPact][PP"] sequence corresponds to swap mark-
ing â€˜0â€™. The next message bit to be embedded is â€˜0â€™.
The two bits match, so swap (2) is not applied, and
the second sentence is sent as it is. So the sent mes-
sage is A1 B C.
The receiver gets this text. He looks at the swap
set to decide which swap may possibly have been
applied to sentence A1. It is only swap (1). In A1 he
detects the sequence adverbâ€“verb. According to pair
(1), this indicates swap marking â€˜1â€™. So, he chooses
â€˜1â€™, which is the first hidden bit. The applicable
swaps for the second sentence are (2) and (3).
Using his secret key, he chooses pair (2). According
to this pair, a sequence of a verb and a PP introduced
by the preposition " corresponds to the marking â€˜0â€™.
He chooses â€˜0â€™, the second hidden bit.
4.5 Security, capacity, and robustness
There are three important aspects to steganography:
security, capacity, and robustness. The security level
determines the (in)ability of an eavesdropper to
â€˜wiretapâ€™ the hidden message. Capacity refers to
the amount of information that can be hidden in
the cover medium, and robustness defines the
amount of modification the cover medium can
withstand without destroying the hidden informa-
tion, or even the cover text in the case of
watermarking.
In the presented approach, security is addressed
in a number of ways:
(1) The number of permissible swaps. The aver-
age number of permissible syntactic alter-
ations per sentence is greater compared to
similar previous approaches (Meral et al.,
2009) due to their shallow nature, and the
linguistic properties of MG that allow for rela-
tively free phrase swapping. Unlike
approaches that allow for the application of
at most one rule to a sentence, the proposed
methodology allows for the application of
more than one phrase swaps at various pos-
itions to a sentence, increasing the number of
generated paraphrases. The greater-than-
average number of legitimate alterations
makes it difficult for an eavesdropper to
decide upon the correct one.
(2) Unlike similar previous approaches that per-
form static marking on the left- and
right-hand side of their syntactic alterations
(Meral et al., 2007), the swap set marking pre-
sented here is based on a cryptographic key.
Thereby only the two communicating parties
can â€˜interpretâ€™ the presence of a specific
phrase bigram as indicating a bit value â€˜0â€™ or
â€˜1â€™. A third party, not familiar with the key,
even if he got a hold of the swap set, would
have to try out all possible markings, in all
K. L. Kermanidis
428 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
possible swap positions of the transmitted
text, a process of significant complexity.
(3) The random manner of choosing the swap to
be performed in case of multiple permissible
swaps. The choice is again based on a crypto-
graphic key, forcing the eavesdropper (if he is
familiar with the swap set) to test all possible
alternatives (perform all possible alterations
to a transmitted sentence). Furthermore, this
â€˜randomnessâ€™ does not allow for any kind of
pattern in the insertion process (the set of
performed syntactic alterations) to be detect-
able by an outsider.
(4) The choice between applying a swap or not.
Even given multiple swap choices for a sen-
tence, the message sender may decide to not
perform any swap at all, and send the sentence
as it is. This adds another degree of freedom
to the steganographic process and another
layer of confusion to the eavesdropper.
(5) The grammaticality of the swap set. The swap
set evaluation in the previous section proved
to be comparable to state of the art
approaches, ensuring the generation of cor-
rect paraphrases. Thereby, looking at a trans-
mitted message, it is very difficult for an
eavesdropper to suspect whether it contains
a hidden message or not.
It has to be noted at this point that security has to be
defined in relation to the profile of the attacker. An
initial question is whether the attacker is familiar
1
â€¦
S1â€™
S2â€™
S3â€™
Sentences 
hiding the 
secret 
message
Checking
for
swap
applicability
Deciding 
whether the 
swap has been 
performed or not 
final 
phrase 
pair set
0
crypto key
marked 
phrase 
pair set
Choosing one 
in case of 
multiple 
permissible 
swaps
crypto 
key
1
0
0
Secret 
message 
bits
Fig. 6 The steps of the message extraction process. For each step the required input is indicated by the vertical arrows
pointing to it
1
â€¦
S1
S2
S3
Cover text 
sentences
Checking
for
swap
applicability
Deciding 
whether to 
perform the 
swap or not 
final 
phrase 
pair set
0
crypto key
marked 
phrase 
pair set
100..101
secet
message
Choosing one 
in case of 
multiple 
permissible 
swaps
crypto 
key
S1â€™
S2â€™
S3â€™
Sentences  
hiding the 
secret 
message
Fig. 5 The steps of the message insertion process. For each step the required input is indicated by the vertical arrows
pointing to it
Linguistic steganography
Literary and Linguistic Computing, Vol. 26, No. 4, 2011 429
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
with the resources, i.e. the utilized swap set. The
degree of freedom might make the informed attack-
erâ€™s job difficult, but it is not impossible to decode
the hidden information, even if the possibilities are
numerous. A way to improve security further and
address this shortcoming is the use of a separate
secret bit string (key), that has comparable length
to that of the hidden message, to encode the mes-
sage, before embedding it, using a bitwise logical
operation of equivalence (e.g. OR) (Bolshakov,
2004). After extracting it, the recipient decodes the
message by performing the reverse logical operation.
The transformed (operated upon) secret message is
now very difficult to extract by a third party that is
not aware of the keys employed.
Another distinction is between a passive and an
active attacker. A passive attacker will wiretap trans-
mitted messages and try to detect those that contain
hidden messages. If he suspects the existence of
hidden information he may try to destroy it by per-
forming changes to the transmitted text. The de-
fense against passive attacks is the imperceptibility
of the secret message, so that the attacker cannot
suspect its existence. An active attacker will ran-
domly attack the communication channel and
change the transmitted text at arbitrary time
points in order to impede any secret communica-
tion between the two parties. The insertion of con-
trol bits along with the secret message bits is the
defense mechanism against such attacks. The con-
trol block is an error correction code that detects
erroneously transmitted bits (bits transmitted by an
illegitimate party), and it may correct up to a spe-
cific number of error bits.
To obtain a feeling of steganographic capacity,
assuming an average word size of 6 bytes/word,
and given that the corpus consists of 166,000
words, the corpus size equals roughly 1-million
bytes. Steganographic capacity (the available band-
width) may be evaluated as follows: using the cur-
rent implementation (with the initial swap set),
which allows for the embedding of one bit per
paraphrase-able sentence, 4,762 (5244482) secret
bits may be embedded in the corpus (the total
number of corpus sentencesâ€”the number of sen-
tences that cannot be paraphrased). In other words,
one bit may be embedded every 1,667 bits of
cover text. Capacity drops slightly after filtering,
i.e. with the reduced swap set, to one embeddable
bit every 1,733 cover text bits. This is still a signifi-
cant improvement over the manually crafted rules
approach (Kermanidis and Magkos, 2009), where
the number of embeddable bits is 4,142 (one
secret bit every 2,000 cover text bits). These calcu-
lations do not include control bits for defense
against attacks, which would lower embedding
density by an order of magnitude (Meral et al.,
2009).
It has been claimed (Chang and Clark, 2010) and
verified here once more that there is a trade-off be-
tween security and capacity: the stricter the syntactic
schemata employed, the more accurate (high secur-
ity) and the less applicable they are (low capacity),
and vice versa. This bandwidth may be further
increased by exploiting the possibility of embedding
more than 1 bits per sentence. This can be achieved
by modifying the information embedding process to
allow bit insertion at every possible swap position in
a sentence. Ideally, a sentence that has X swap pos-
itions, will allow for hiding X secret bits. This is an
innovative potential offered by the proposed meth-
odology, as all syntactic transformation approaches
in the literature lead to a capacity of 0.5â€“1 bits/sen-
tence (Meral et al., 2009), and constitutes an inter-
esting future research direction. Approaches
adopting synonym substitution achieve higher cap-
acity values, due to the possibility of multiple word
substitutions within a sentence. For example
Bolshakov (2004) reports a capacity factor of one
hidden bit for every 250 cover text bits. However,
as mentioned earlier, they are very resource de-
manding. The presented approach is robust and ad-
equately secure to be used for hiding without too
much fuss (sophisticated pre-processing) small
secret messages underneath any MG text, when de-
fense against destruction attacks is not a primary
concern, but only transmitting a non-detectable
message.
5 Conclusion
This work presented a novel methodology for the
automatic generation of MG shallow paraphrases.
K. L. Kermanidis
430 Literary and Linguistic Computing, Vol. 26, No. 4, 2011
 at U
B Leipzig on January 4, 2012
http://llc.oxfordjournals.org/
D
ow
nloaded from
 
The approach utilizes limited external linguistic re-
sources, making the process easily portable to other
languages that have a similar syntactic freedom to
MG. The methodology is robust, i.e. it can be
applied to any MG text, and domain independent.
The statistical significance of the co-occurrence of
phrase bigrams is measured, and phrase pairs that
are highly correlated in both orderings form the
initial swap set. To improve paraphrasing perform-
ance, a supervised SVMs filter, taking into account
the morphosyntactic context in which the alteration
is to take place, reduces the number of generated
swapping schemata by removing schemata that are
strongly correlated to erroneous syntactic
transformations.
The correctness and the significant number of
the extracted paraphrases render them useful for
steganographic communication. The syntactic
transformations make it possible to hide secret bits
underneath a cover text, and a third party is unable
to detect the applied transformations and decide
upon the correct ones (and therefore unable to ex-
tract the hidden message). Apart from the innova-
tive way of generating correct and significant in
number paraphrases, the ability to perform multiple
alterations (swaps) within a single sentence offers
novel potential for enhancing steganographic secur-
ity and capacity.
It would be interesting to explore the use of other
filters (other than supervised learning) in order to
remove erroneous candidate phrase swaps from the
sets derived using the statistical significance metrics.
Another challenging perspective would be to in-
crease the depth of the transformations, e.g. to en-
large the window size between the phrases to be
swapped, instead of focusing only on two consecu-
tive chunks. This would increase paraphrasing ac-
curacy (coordinating schemata would be dealt with,
more distant dependencies would be addressed,
etc.) and make it more complicated for a malicious
party to detect the underlying syntactic transform-
ations. In this case, however, correct swapping
would require carefully set morphosyntactic restric-
tions on the context surrounding the swap.
Regarding steganography, an interesting future re-
search objective is taking advantage of the multiple
swap positions in most sentences to hide more than
one bits within a single sentence, thus increasing
steganographic capacity.
The application areas of the presented paraphras-
ing generation methodology are not limited to lin-
guistic steganography. An initial version of the
methodology, that makes use of a small number of
handcrafted rules for producing permissible swaps,
has been proposed to be applied to the area of lan-
guage learning (Kermanidis, 2009) for partial syntax
checking or as a support tool for teachers and exam
designers. It may also be employed for authoring
support that provides the author with suggestions
about how to form his/her text, for language gener-
ation, summarization (create a summary with an
altered syntax), and question answering.