The Role of the Computer in
Humanities Computing
Wilhelm Ott (wilhelm.ott@uni-tuebingen.de)
Tübingen University
Professor Ott delivered the 2007 Busa Prize Lecture under this
title. What follows is the introduction to the lecture, provided
by Michael Sperberg-McQueen.
As John Unsworth has just said, the fourth Busa Award is given
to Wilhelm Ott. The members of the committee for this cycle
of the Busa Award were:
• Lorna Hughes (chair)
• Lisa Lena Opas-Hänninen
• Espen Ore
• Steve Ramsay
• Stefan Sinclair
The members of the Award committee have asked me to say a
few words about the work of Wilhelm Ott.
Like many of us, Wilhelm Ott came to our field by a circuitous
route.
As a young man, he studied at the Collegium Germanicum, a
seminary in Rome, but, if I understand correctly, he experienced
some tensions with his superiors. As in the traditional university,
a four-year study of the liberal arts was required before students
were allowed to embark on the study of the queen of sciences,
theology. Herr Ott and some of his fellow students incurred the
displeasure of the authorities by sneaking across the road in
some otherwise unoccupied time, to sit in on a series of lectures
on Paul's epistle to the Romans.
And then, in his master's thesis, that chapter on Heidegger!
Well, really.
Let's say just that when he continued his education elsewhere,
it was a mutual decision.
It was natural, perhaps, that from theology he should turn to
classical philology. As a student of modern languages, I have
always envied classicists their extensive set of ancillary tools,
their lexica, their dictionaries, their handbooks.
But to someone coming to classics from theology and Biblical
literature, of course, what seems most striking classics is the
striking poverty of the instrumentarium. Specialized glossaries
Page 147
Digital Humanities 2007
and grammars for individual authors, concordances, systematic
lists of all kinds were much less thick on the ground than one
might wish.
And so, characteristically, he set out to help fill this gap.
His first work in this vein is a series of books published
beginning in 1970 providing tables and data for the systematic
study of the Latin hexameter: first of all a volume of Metrische
Analysen zur Ars poetica des Horaz, which provides tables of
scansions, elision, ictus, and related information for each line
of Horace's poem,modeled on similar tables for metrical studies
provided by Eduard Norden in his edition of the Aeneid.
Similar volumes followed, over the years, for the twelve books
of Vergi's Aeneid, for the Georgica and the Bucolica, for
Lucretius, and so on.
In the Foreword to the volume on Book VI of the Aeneid, there
appears a sentence which seems to sum up, programmatically,
both the capabilities and the potential limits of digital
processing:
Electronic data processing can be put into service whenever
data of any kind—notably including texts—must be processed
according to rules which are unambiguously formulatable and
completely formalizable.
What more compact formulation could we find of the
fundamental program of our field? And what more matter of
fact reminder that this is a description of those places where
computers can successfully be deployed, without any suggestion
of belief that they can be deployed absolutely everywhere.
The metrical tools set an emphasis which has continued to
characterize all of Herr Ott's work throughout his career:
computers should serve scholarly purposes, not vice versa. In
his discussion of the tables and their preparation, three virtues
are seen as particularly important:
• completeness
• reliability
• verifiability
All of these concerns characterize Herr Ott's later work as well.
There is, too, a concern for accessibility. Initially, it motivated
the publication of the metrical analyses in book form, to make
them accessible to classicists without compuational expertise
or means. Later, the concern for accessibility led to efforts to
make the software which generated those analyses accessible
to other scholars, to extend them to make a more tool useful
for other kinds of analysis as well. In due course, these efforts
produced a suite of programs for scholarly work with text,
which at some point acquired the name Tustep, the Tübingen
System of Text Processing tools.
Tustep embodied a number of important ideas:
• completeness: It can be used for all parts of a project's
normal work. There is an editor for data capture and
revision, there are copy commands and tape utilities for
archiving and moving data, there are a variety of general
and specialized proceessing tools for manipulating
documents, for sorting things, for extracting relevant items
from lists, for laying documents out on the page, for
photocomposition of the resulting pages, and so on.)
• verifiability: Every action undertaken with Tustep will be
logged, unless you take very active steps to avoid having it
logged.
• stability: Since projects may live for years or decades, the
stability of the program and of Tustep files is critically
important.
• consistency: Years before anyone outside of Bell Labs had
heard of Unix, Tustep adopted the principle that every tool
would have one primary input and one primary output, and
that the output of every tool would be usable as the input
to any other tool. In practice, this means that the primary
input and the primary output of each tool use the Tustep
file format.
This principle of ensuring that other Tustep programs can read
the primary output of any Tustep program is consistently
implemented, even in cases where one might have expected a
different choice. When I learned that the typesetting program
of Tustep also produces a Tustep file as its output — the PDF
or photocomposer file is, formally speaking, a side effect — I
admired the consistent application of the design principle but
privately thought that it bordered on the academic. Since for
practical purposes the main output of a typesetting program is
typeset pages, producing a Tustep file seems likely to be an
anticlimax. What useful output can it produce? Perhaps just a
copy of its input?
The most important idea of Tustep, though, is that it is the
responsibility of the software to serve the needs of scholarship,
and not vice versa, and that the responsibility of the scholar is
to respect the significant particularities of the material and the
demands of his discipline (not any standards of practice imposed
from outside, and least of all any limitations imposed by the
software.)
Tustep developed over thirty years of listening to the needs of
scholarship, consulting with projects and adding to Tustep the
functionality they needed to enable them to do their work.
Hundreds of editions have been prepared with it, some all the
way from beginning to end, from data capture through typeset
pages, others just translated into Tustep for the typesetting —
apparatus criticus is not easy to set!
If we are to take responsibility, as humanists, for our use of
machines, then it is necessarily now a part of humanities
scholarship to understand and develop ways to make machines
Page 148
Digital Humanities 2007
adapt to the requirements of our work, and (while remaining
open to the exploitation of new and unforeseen opportunities)
to resist the temptation to adjust our practices to suit the
convenience of the machine. In this sense, Wilhelm Ott's
decades of work on Tustep have been not only the work of a
software developer, but more profoundly the work of a gifted
humanist.
It has been the great good fortune of our field to benefit from
Wilhelm Ott's work as a scholar. His work has taught a great
deal over the years to those wise enough to learn from it. And
I for one am grateful for the chance, this evening, to learn from
him in person.
