The	Artificial	Intelligence	(AI)	
Hermeneutic Network:  Toward 
an Approach to Analysis and 
Design of Intentional Systems 
Jichen Zhu 
Georgia Institute of Technology 
jichen.zhu@lcc.gatech.edu
 
D. Fox Harrell, Ph.D.  
Georgia Institute of Technology  
fox.harrell@lcc.gatech.edu	
‘I felt that I should be able to get the computer to sound 
good more or less on its own, so that someone listening 
to	it	says,	“Who	is	that	playing?”	But	if	you	get	“What’s	
that?”	instead,	you	have	to	go	back	to	the	drawing	board.’	
(Lewis, 2000) 
Abstract 
Digital information technologies are increasingly being adopted in the humanities as both research 
tools and supports for new forms of cultural expression. 
Some	of	these	digital	technologies,	in	particular	artificial	
intelligence (AI) programs, exhibit complex behaviors 
usually seen as the territory of intentional human phe-
nomena, such as creativity, planning and learning. This 
paper	identifies	a	prototypical	subset	of	these	programs,	
which we name intentional systems, and argues that their 
seemingly intentional behaviors are not the sole effect of 
underlying algorithmic complexity and knowledge engi-
neering practices from computer science. In contrast, we 
argue	(paralleling	the	field	of	software	studies)	that	in-
tentional systems, and digital systems at large, need to be 
analyzed as a contemporary form of historically, cultur-
ally, socially, and technically situated texts. Perception 
of system intentionality arises from a network of con-
tinuous	meaning	exchange	between	system	authors’	nar-
ration	and	users’	interpretation	processes	embedded	in	a	
broader social context. The central contribution of this 
paper is a new interdisciplinary analytical framework 
called the AI hermeneutic network that is informed by 
traditions of hermeneutic analysis, actor-network theory, 
cognitive semantics theory, and philosophy of mind. To 
illustrate the design implication of the AI hermeneutic 
network, we present our recent work Memory, Reverie 
Machine, an expressive intentional system that generates 
interactive narratives rich with daydreaming sequences. 
Intentional Systems 
Trombonist	 and	 composer	 George	 Lewis’s	 above	 de-
DIGITAL HUMANITIES 2009
Page 302
scription of his interactive musical system Voyager ex-
emplifies	a	growing	number	of	digital	systems,	such	as	
the autonomous painting program AARON (Cohen 2002) 
and recent computational narrative works (Harrell 2006; 
Mateas	&	Stern	2002;	PŽrez	y	PŽrez	&	Aliseda	2006),	
that utilize AI techniques in pursuit of cultural expres-
sion. Decades after heated debates about the feasibility 
of AI, the question of whether computers may one day 
possess human-level intelligence no longer spurs soci-
ety’s	fear	and	curiosity.	Instead,	systems	are	designed	to	
encourage users to make sense of them as intentional and 
independent entities. Compared to instrumental, produc-
tion-oriented programs such as the PhotoShop, these 
systems display intentional behaviors related to human 
mental phenomena such as planning, learning, narrating, 
and creating, as if their actions were about something in 
the world (Searle 1983) rather than mere execution of 
algorithmic rules. Lewis, for instance, insists that Voy-
ager ‘not [be] treated as a musical instrument, but as an 
independent	 improviser.’	 He	 deliberately	 designed	 the	
system to display independent behaviors arising from 
its own internal processes that even its designer cannot 
fully anticipate. The improvisational dialogue between 
Voyager and the musicians, Lewis emphasizes, is ‘bi-di-
rectional	transfer	of	intentionality	through	sound.’	com-
putational complexity, 2) process opacity, 3) human-like 
coherent behaviors, and 4) execution of authorial inten-
tion. The term encompasses not only AI systems but also 
AI-like systems that exist either outside of computer sci-
ence communities or are not described by their authors 
as AI systems for ideological or other reasons. Critical 
analysis and design of intentional systems, like informa-
tion technologies at large in the digital humanities, calls 
for the recognition of these systems as important forms 
of cultural production, beyond their traditionally instru-
mentalized, productivity oriented roles. 
Intentional Systems as Texts 
Although generally used to describe written forms of dis-
course, the term text as the object of literary theory and 
modern	hermeneutics	 is	not	confined	 to	only	 linguistic	
forms. In his essay on the literary text, German philoso-
pher Manfred Frank (Frank 1989) criticizes the notion 
that meanings that authors encode within texts can be 
objectively retrieved without distortion by readers given 
appropriate methods of interpretation (Hirsch 1967). In-
stead, Frank proposes a complex communication process 
in which both author and reader actively create, shape, 
and reconstruct meanings. This echoes the even broader 
notion of dialogic meaning posited by the Russian phi-
losopher and critic Mikhail Bakhtin in which language 
is understood as dynamic, contextual, intertextual, and 
relational (Holquist 1990). Acknowledging the textuality 
of intentional systems opens up understanding of system 
intentionality to a range of socially situated methods. 
Intentional systems are not simply the result of clever 
algorithmic and data structural innovations. The AI 
practitioner and theorist Philip Agre cogently points out 
that the ‘the purpose of AI is to build computer systems 
whose operation can be narrated using intentional vocab-
ulary.’	(Agre	1997)	Michael	Mateas,	co-developer	of	Fa-
çade, further deconstructs the codes invoked in AI prac-
tice	by	computation,	and	definitions	of	system	progress)	
and	 the	co-existing	‘code	machine’	(including	physical	
processes, computational processes, and complex causal 
flow),	in	order	to	pin	down	the	long-neglected	social	and	
discursive aspect of AI systems (Mateas 2002). In ad-
dition to considering actual computer programs, analy-
sis	 of	 intentional	 systems	 should	not	omit	 the	 authors’	
publications, presentations, and interpersonal communi-
cation about the system. Such narrative outputs situate 
the	system	in	AI	research	communities	and	frame	users’	
interpretation, and therefore must be considered as part 
of the intentional system. 
The AI Hermeneutic Network 
The central contribution of this paper is the AI herme-
neutic network model, enabled by theorizing intentional 
systems as texts. The interdisciplinary framework ana-
lyzes system intentionality as a result of a hermeneutic 
communication	process	that	involves	both	authors’	nar-
rations	 and	 users’	 interpretations	 through	 interaction	
with	both	actual	systems	and	authors’	narrative	output.	
In addition, this paper recognizes that intentional sys-
tems exist in broader social contexts that involve more 
than just authors and users. Animate and inanimate ac-
tors,	 called	 ‘actants’	 in	 actor-network	 theory	 (Callon	
1986; Latour 1996), participate in the network through 
multi-directional communication. Government and mili-
tary funding, for instance, often plays a prominent role in 
determining direction and validity of different approach-
es of AI research. 
Historically, hermeneutic studies developed interpreta-
tive theories and methods in order to recover the mean-
ings of sacred texts intended by the (divine) author(s). 
Modern	 hermeneutics,	 influenced	 by	 Schleiermacher,	
recognizes that everything calls for the work of inter-
pretation and broadens itself to the philosophical inter-
rogation of interpretation (Virkler 1981). This paper 
highlights	 discursive	 ‘elasticity’	 of	 the	AI	 key	 words,	
such as planning (Agre 1997). He observes that these 
key terminologies are simultaneously precise (formal) 
and vague (vernacular), which allows AI practitioners 
to seamlessly integrate their everyday experience as em-
bodied intentional being in the algorithmic research, and 
to narrate computation with popularly accessible ver-
DIGITAL HUMANITIES 2009
Page  303
nacular vocabulary.  
One relatively unexplored aspect of this continuous ne-
gotiation of values and meanings between both human 
and	computational	 actors	 (Latour	1996)	 is	users’	 read-
ings and interpretations of intentionality from systems 
that are clearly inanimate. For example, human co-
performers	 and	 their	 audiences’	 interpretations	of	Voy-
ager’s	behaviors	as	intentional	are	central	to	construe	the	
systems’	status	as	an	independent	performer	in	its	own	
right, as intended by its designer. Frank argues that ‘[i]
n the understanding of its readers the text … acquires a 
meaning	which	exceeds	the	memory	of	its	origin.’(Frank	
1989) Any analysis of system intentionality then is not 
adequate without considering participation of users and 
audiences.  
This paper emphasizes the discursive strategy and se-
mantic interpretation from a cognitive linguistics per-
spective. Conceptual blending theory (Fauconnier 2001; 
Fauconnier & Turner 2002; Turner 1996) offers a cogni-
tive foundation for understanding system intentionality 
as actively (re)constructed by users via integrating con-
cepts of intentionality based on encounters with animate 
agents, and conceptualization of algorithmic operation 
of inanimate computer systems. Thus, users compress 
the behavior of unfamiliar computational systems to hu-
man scale by constructing conceptual blends of systems 
with human-like intentionality, through semantic hooks 
that facilitate such blends in the various discourses sur-
rounding the systems.  
Conclusion:  Design Implications of the AI 
Hermeneutic Network
The novel framework of the hermeneutic network sug-
gests new design approaches for intentional systems in 
digital humanities. Our current interactive narrative work 
Memory, Reverie Machine generates stories in which the 
main character varies dynamically along a scale between 
a user-controlled avatar with low intentionality and an 
autonomous non-player character with high intentional-
ity. By algorithmically controlling the semantic hooks 
for interpreting system behavior as intentional in the nar-
rative discourse (Zhu & Harrell 2008), the authors turn 
system intentionality into a scalable expressive dimen-
sion in interactive storytelling (Harrell & Zhu 2009). 
In conclusion, this paper proposes a new interdisciplin-
ary framework to analyze intentional systems as social 
and cultural productions, as opposed to construing them 
as the domain of purely technical practices. It underlines 
authors’	narrative	and	users’	interpretative	strategies,	in	a	
socially situated network of meaning exchange. Finally, 
through our own computational work we suggest new 
design implications for intentional systems, such as the 
scale of intentionality (Zhu & Harrell 2008) that poten-
tially can add new forms of expressivity to intentional 
systems in digital humanities. 
References
Agre, P. E. (1997). ‘Toward a Critical Technical Prac-
tice:	Lessons	Learned	 in	Trying	 to	Reform	AI’,	 in	So-
cial Science, Technical Systems, and Cooperative Work: 
Beyond the Great Divide, eds G. C. Bowker, S. L. Star, 
W. Turner, L. Gasser & G. Bowker, Lawrence Erlbaum 
Associates, pp. 131-58. 
Callon, M. (1986). ‘Some Elements of a Sociology of 
Translation: Domestication of the Scallops and the Fish-
ermen	of	St	Brieuc	Bay’,	in	Power, Action and Belief: A 
New Sociology of Knowledge, ed. J. Law, Routledge & 
Kegan Paul, London. 
Cohen, H.	 (2002).	 ‘A	 Self-Defining	 Game	 for	 One	
Player: On the Nature of Creativity and the Possibility 
of	Creative	Computer	Programs’,	Leonardo, vol. 35, no. 
1, pp. 59-64. 
Fauconnier, G. (2001). ‘Conceptual Blending and Anal-
ogy’,	 in	The Analogical Mind: Perspectives from Cog-
nitive Science, eds D. Gentner, K. J. Holyoak & B. N. 
Kokino, MIT Press, Cambridge, MA. 
Frank, M. (1989). The Subject and the Text: Essays on 
literary theory and philosophy, Cambridge University 
Press, Cambridge. 
Harrell, D. F. (2006). Walking Blues Changes Under-
sea: Imaginative Narrative in Interactive Poetry Genera-
tion with the GRIOT System, paper presented to AAAI 
2006	Workshop	 in	Computational	Aesthetics:	Artificial	
Intelligence Approaches to Happiness and Beauty, Bos-
ton, MA, AAAI Press. 
Hirsch, E. D. (1967). Validity in Interpretation Yale 
University Press, New Haven and London. 
Holquist, M. (1990). Dialogism: Bakhtin and His 
World, 2 edn. 
Latour, B. (1996). Aramis, or the Love of Technology, 
Harvard University Press, Cambridge. 
Mateas, M.	 (2002).	Interactive	Drama,	Art,	and	Artifi-
cial Intelligence, Carnegie Mellon University. 
Searle, J. (1983). Intentionality: An Essay in the Philos-
DIGITAL HUMANITIES 2009
Page 304
ophy of Mind, Cambridge University Press, Cambridge. 
Turner, M. (1996). The Literary Mind: The Origins of 
Thought and Language, Oxford UP, New York; Oxford. 
Virkler, H. A. (1981). Hermeneutics: Principles and 
Processes of Biblical Interpretation, Baker Book House, 
Grand Rapids, MI. 
Fauconnier, G. & Turner, M. (2002). The Way We 
Think: Conceptual Blending and the Mind’s Hidden 
Complexities, Basic Books. 
Harrell, D. F. & Zhu, J. (2009). Agency Play: Dimen-
sions of Agency for Interactive Narrative Design, paper 
presented to to appear in the Proceeding of AAAI Spring 
2009 Symposium on Interactive Narrative Technologies 
II. 
Mateas, M. & Stern, A. (2002). ‘A Behavior Language 
for	 Story-Based	 Believable	 Agents’,	 IEEE Intelligent 
Systems, vol. 17, no. 4, pp. 39-47. 
Pérez y Pérez, R. & Aliseda, A. (2006). The Role of 
Abduction in Automatic Storytelling, paper presented to 
Proceedings of the AAAI workshop in Computational 
Aesthetics: AI Approaches to Beauty & Happiness, Bos-
ton, MA, AAAI Press, pp. 53-60. 
Zhu, J. & Harrell, D. F. (2008). Daydreaming with In-
tention: Scalable Blending-Based Imagining and Agency 
in Generative Interactive Narrative, paper presented to 
AAAI 2008 Spring Symposium on Creative Intelligent 
Systems, Stanford, CA, AAAI Press, pp. 156-62. 
